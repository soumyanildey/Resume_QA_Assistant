{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "45525830f6a343368e3cb0bf6f73138b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2e1502a57fe44486b9db2b7cf4d73493",
              "IPY_MODEL_78e43b73886d477bbfe83b12e44ed74b",
              "IPY_MODEL_4be6b7ec97e84a4fac026fdddd1a4573"
            ],
            "layout": "IPY_MODEL_9ee1707c7d034f48a6b6549b0aba02be"
          }
        },
        "2e1502a57fe44486b9db2b7cf4d73493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c03fae6f9e9486db2f02d25ed079a52",
            "placeholder": "​",
            "style": "IPY_MODEL_fa59cf37763b4371af7047d5573a9fd7",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "78e43b73886d477bbfe83b12e44ed74b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_111fd4917a4f4a53a759c10f8390ce4a",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_29342c8faaab456684b3f77555bbfcf2",
            "value": 4
          }
        },
        "4be6b7ec97e84a4fac026fdddd1a4573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51d9a6c6167c4c16906c3aea39abbd48",
            "placeholder": "​",
            "style": "IPY_MODEL_44498007c1364fa79da5d6975af521e6",
            "value": " 4/4 [01:55&lt;00:00, 26.02s/it]"
          }
        },
        "9ee1707c7d034f48a6b6549b0aba02be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c03fae6f9e9486db2f02d25ed079a52": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa59cf37763b4371af7047d5573a9fd7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "111fd4917a4f4a53a759c10f8390ce4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29342c8faaab456684b3f77555bbfcf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "51d9a6c6167c4c16906c3aea39abbd48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44498007c1364fa79da5d6975af521e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwQnhIs5jFwi",
        "outputId": "d4b65ae7-8fa0-4940-88e1-dc17fedec6cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-index in /usr/local/lib/python3.11/dist-packages (0.13.0)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (5.0.0)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.11/dist-packages (0.46.1)\n",
            "Requirement already satisfied: llama-index-embeddings-huggingface in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: llama-index-llms-huggingface in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: llama-index-cli<0.6,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.5.0)\n",
            "Requirement already satisfied: llama-index-core<0.14,>=0.13.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.13.0)\n",
            "Requirement already satisfied: llama-index-embeddings-openai<0.6,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.5.0)\n",
            "Requirement already satisfied: llama-index-indices-managed-llama-cloud>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.9.0)\n",
            "Requirement already satisfied: llama-index-llms-openai<0.6,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.5.0)\n",
            "Requirement already satisfied: llama-index-readers-file<0.6,>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.5.0)\n",
            "Requirement already satisfied: llama-index-readers-llama-parse>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from llama-index) (0.5.0)\n",
            "Requirement already satisfied: nltk>3.8.1 in /usr/local/lib/python3.11/dist-packages (from llama-index) (3.9.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.54.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.34.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.14.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from bitsandbytes) (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (3.12.15)\n",
            "Requirement already satisfied: aiosqlite in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index) (0.21.0)\n",
            "Requirement already satisfied: banks<3,>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index) (2.2.0)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index) (0.6.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index) (1.2.18)\n",
            "Requirement already satisfied: dirtyjson<2,>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index) (1.0.8)\n",
            "Requirement already satisfied: filetype<2,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index) (1.2.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index) (0.28.1)\n",
            "Requirement already satisfied: llama-index-workflows<2,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index) (1.2.0)\n",
            "Requirement already satisfied: nest-asyncio<2,>=1.5.8 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index) (3.5)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index) (4.3.8)\n",
            "Requirement already satisfied: pydantic>=2.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index) (2.11.7)\n",
            "Requirement already satisfied: setuptools>=80.9.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index) (80.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.49 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index) (2.0.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.2.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index) (8.5.0)\n",
            "Requirement already satisfied: tiktoken>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from llama-index-core<0.14,>=0.13.0->llama-index) (1.17.2)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.98.0)\n",
            "Requirement already satisfied: llama-cloud==0.1.35 in /usr/local/lib/python3.11/dist-packages (from llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (0.1.35)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.11/dist-packages (from llama-cloud==0.1.35->llama-index-indices-managed-llama-cloud>=0.4.0->llama-index) (2025.7.14)\n",
            "Requirement already satisfied: beautifulsoup4<5,>=4.12.3 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (4.13.4)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.7.1)\n",
            "Requirement already satisfied: pandas<2.3.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.2.2)\n",
            "Requirement already satisfied: pypdf<6,>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (5.9.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-file<0.6,>=0.5.0->llama-index) (0.0.26)\n",
            "Requirement already satisfied: llama-parse>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.53)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk>3.8.1->llama-index) (2024.11.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.4)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: accelerate>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (1.9.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate>=0.26.0->transformers[torch]<5,>=4.37.0->llama-index-llms-huggingface) (5.9.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->huggingface-hub[inference]>=0.19.0->llama-index-embeddings-huggingface) (1.20.1)\n",
            "Requirement already satisfied: griffe in /usr/local/lib/python3.11/dist-packages (from banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4<5,>=4.12.3->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.7)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx->llama-index-core<0.14,>=0.13.0->llama-index) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx->llama-index-core<0.14,>=0.13.0->llama-index) (0.16.0)\n",
            "Requirement already satisfied: llama-index-instrumentation>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from llama-index-workflows<2,>=1.0.1->llama-index-core<0.14,>=0.13.0->llama-index) (0.4.0)\n",
            "Requirement already satisfied: llama-cloud-services>=0.6.53 in /usr/local/lib/python3.11/dist-packages (from llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (0.6.53)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai>=1.1.0->llama-index-embeddings-openai<0.6,>=0.5.0->llama-index) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.8.0->llama-index-core<0.14,>=0.13.0->llama-index) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.49->sqlalchemy[asyncio]>=1.4.49->llama-index-core<0.14,>=0.13.0->llama-index) (3.2.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect>=0.8.0->llama-index-core<0.14,>=0.13.0->llama-index) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json->llama-index-core<0.14,>=0.13.0->llama-index) (3.26.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: python-dotenv<2.0.0,>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from llama-cloud-services>=0.6.53->llama-parse>=0.5.0->llama-index-readers-llama-parse>=0.4.0->llama-index) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<2.3.0->llama-index-readers-file<0.6,>=0.5.0->llama-index) (1.17.0)\n",
            "Requirement already satisfied: colorama>=0.4 in /usr/local/lib/python3.11/dist-packages (from griffe->banks<3,>=2.2.0->llama-index-core<0.14,>=0.13.0->llama-index) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U llama-index sentence-transformers bitsandbytes llama-index-embeddings-huggingface llama-index-llms-huggingface llama-index"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_cloud_services import LlamaExtract\n",
        "import os\n",
        "os.environ[\"LLAMA_CLOUD_API_KEY\"] = '<YOUR_API_KEY>'\n",
        "\n",
        "project_id='<your_project_id>'\n",
        "\n",
        "def load_extractor(project_id,agent_name):\n",
        "  llama_extract = LlamaExtract(project_id=project_id)\n",
        "  agent = llama_extract.get_agent(name=\"Precise_Resume_extract\")\n",
        "  print(agent.data_schema)\n",
        "  return agent\n",
        "\n",
        "extractor = load_extractor(project_id,'Precise_Resume_extract')"
      ],
      "metadata": {
        "id": "h0LkzmX8AOnn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ce7c47-a71a-4282-813a-9f26977a3954"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'additionalProperties': False, 'properties': {'basics': {'additionalProperties': False, 'properties': {'name': {'description': 'The full name of the candidate', 'type': 'string'}, 'email': {'description': 'The email address of the candidate', 'type': 'string'}, 'phone': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'description': 'The phone number of the candidate in any standard format'}, 'location': {'anyOf': [{'additionalProperties': False, 'description': 'The current location of the candidate', 'properties': {'city': {'description': 'The city where the candidate is located', 'type': 'string'}, 'region': {'description': 'State or province of the candidate', 'type': 'string'}, 'country': {'description': 'Country where the candidate is located', 'type': 'string'}}, 'required': ['city', 'region', 'country'], 'type': 'object'}, {'type': 'null'}]}, 'profiles': {'anyOf': [{'items': {'additionalProperties': False, 'properties': {'network': {'description': 'Name of the social network (e.g., LinkedIn, GitHub)', 'type': 'string'}, 'url': {'description': 'Full URL to the profile', 'type': 'string'}}, 'required': ['network', 'url'], 'type': 'object'}, 'type': 'array'}, {'type': 'null'}]}, 'summary': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'description': 'Brief professional summary or objective statement'}}, 'required': ['name', 'email', 'phone', 'location', 'profiles', 'summary'], 'type': 'object'}, 'skills': {'description': 'Technical and professional skills grouped by category', 'items': {'additionalProperties': False, 'properties': {'category': {'description': 'Skill category (e.g., Programming Languages, Tools, Soft Skills)', 'type': 'string'}, 'keywords': {'description': 'List of specific skills within the category', 'items': {'type': 'string'}, 'type': 'array'}, 'level': {'enum': ['beginner', 'intermediate', 'advanced', 'expert'], 'type': 'string', 'description': 'Proficiency level in this skill category'}}, 'required': ['category', 'keywords', 'level'], 'type': 'object'}, 'type': 'array'}, 'experience': {'description': 'Professional work experience in reverse chronological order', 'items': {'additionalProperties': False, 'properties': {'company': {'description': 'Name of the employer or company', 'type': 'string'}, 'position': {'description': 'Job title or role', 'type': 'string'}, 'startDate': {'description': 'Start date of employment (YYYY-MM or YYYY-MM-DD)', 'type': 'string'}, 'endDate': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'description': \"End date of employment (YYYY-MM or YYYY-MM-DD), or 'Present' if current\"}, 'highlights': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}]}, 'technologies': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}]}}, 'required': ['company', 'position', 'startDate', 'endDate', 'highlights', 'technologies'], 'type': 'object'}, 'type': 'array'}, 'education': {'anyOf': [{'items': {'additionalProperties': False, 'properties': {'institution': {'type': 'string'}, 'degree': {'type': 'string'}, 'field': {'anyOf': [{'type': 'string'}, {'type': 'null'}]}, 'graduationDate': {'anyOf': [{'type': 'string'}, {'type': 'null'}]}, 'gpa': {'anyOf': [{'type': 'number'}, {'type': 'null'}]}}, 'required': ['institution', 'degree', 'field', 'graduationDate', 'gpa'], 'type': 'object'}, 'type': 'array'}, {'type': 'null'}]}, 'certifications': {'anyOf': [{'items': {'additionalProperties': False, 'properties': {'name': {'type': 'string'}, 'issuer': {'anyOf': [{'type': 'string'}, {'type': 'null'}]}, 'date': {'type': 'string'}, 'validUntil': {'anyOf': [{'type': 'string'}, {'type': 'null'}]}}, 'required': ['name', 'issuer', 'date', 'validUntil'], 'type': 'object'}, 'type': 'array'}, {'type': 'null'}]}, 'publications': {'anyOf': [{'items': {'additionalProperties': False, 'properties': {'title': {'type': 'string'}, 'publisher': {'type': 'string'}, 'date': {'type': 'string'}, 'url': {'type': 'string'}}, 'required': ['title', 'publisher', 'date', 'url'], 'type': 'object'}, 'type': 'array'}, {'type': 'null'}]}}, 'required': ['basics', 'skills', 'experience', 'education', 'certifications', 'publications'], 'type': 'object'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_data = extractor.extract('/content/Backend AI Engineer Resume Template - Claude.pdf')\n",
        "print(parsed_data.data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iILQxYXfQsdU",
        "outputId": "7fbff0d8-46fb-4bd3-d855-167ab07c6188"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Uploading files: 100%|██████████| 1/1 [00:00<00:00,  1.76it/s]\n",
            "Creating extraction jobs: 100%|██████████| 1/1 [00:00<00:00,  1.03it/s]\n",
            "Extracting files: 100%|██████████| 1/1 [00:35<00:00, 35.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'basics': {'name': 'Alexandra Chen', 'email': 'alexandra.chen@email.com', 'phone': '+1 (555) 123-4567', 'location': {'city': 'San Francisco', 'region': 'CA', 'country': 'USA'}, 'profiles': [{'network': 'LinkedIn', 'url': 'https://linkedin.com/in/alexandrachen'}, {'network': 'GitHub', 'url': 'https://github.com/alexchen-dev'}], 'summary': 'Accomplished Senior Backend AI Engineer with 8+ years of experience designing and implementing scalable, high-performance backend systems and AI/ML solutions. Proven track record of leading cross-functional teams to deliver enterprise-grade applications serving millions of users. Expertise in distributed systems, microservices architecture, machine learning pipelines, and cloud-native technologies. Passionate about leveraging cutting-edge AI technologies to solve complex business problems while maintaining system reliability and performance.'}, 'skills': [{'category': 'Programming Languages', 'keywords': ['Python', 'Java', 'Scala', 'Go', 'C++', 'JavaScript/TypeScript', 'SQL', 'R'], 'level': 'expert'}, {'category': 'AI/ML Technologies', 'keywords': ['TensorFlow', 'PyTorch', 'Scikit-learn', 'Keras', 'XGBoost', 'LightGBM', 'MLflow', 'Kubeflow', 'Apache Airflow', 'DVC', 'Weights & Biases', 'TensorFlow Serving', 'TorchServe', 'ONNX Runtime', 'Triton Inference Server', 'Transformers', 'BERT', 'GPT', 'spaCy', 'NLTK', 'Hugging Face', 'OpenCV', 'PIL', 'Detectron2', 'YOLO', 'OpenAI Gym', 'Stable Baselines3', 'Ray RLlib'], 'level': 'expert'}, {'category': 'Backend Technologies', 'keywords': ['Django', 'FastAPI', 'Flask', 'Spring Boot', 'Express.js', 'Gin', 'Echo', 'PostgreSQL', 'MongoDB', 'Redis', 'Cassandra', 'ClickHouse', 'Neo4j', 'Apache Kafka', 'RabbitMQ', 'Amazon SQS', 'Apache Pulsar', 'Elasticsearch', 'Apache Solr', 'Amazon OpenSearch', 'REST', 'GraphQL', 'gRPC', 'WebSockets'], 'level': 'expert'}, {'category': 'Cloud Platforms', 'keywords': ['AWS', 'Google Cloud Platform', 'Microsoft Azure'], 'level': 'advanced'}, {'category': 'Container Technologies', 'keywords': ['Docker', 'Kubernetes', 'Helm', 'Istio'], 'level': 'advanced'}, {'category': 'Infrastructure as Code', 'keywords': ['Terraform', 'CloudFormation', 'Ansible'], 'level': 'advanced'}, {'category': 'Monitoring', 'keywords': ['Prometheus', 'Grafana', 'ELK Stack', 'Datadog', 'New Relic'], 'level': 'advanced'}, {'category': 'CI/CD', 'keywords': ['Jenkins', 'GitLab CI', 'GitHub Actions', 'CircleCI'], 'level': 'advanced'}, {'category': 'Data Engineering', 'keywords': ['Apache Spark', 'Apache Beam', 'Apache Flink', 'Databricks', 'Snowflake', 'BigQuery', 'Redshift'], 'level': 'advanced'}, {'category': 'Languages', 'keywords': ['English (Native)', 'Mandarin Chinese (Fluent)', 'Spanish (Conversational)'], 'level': 'advanced'}, {'category': 'Leadership & Soft Skills', 'keywords': ['Technical Team Leadership', 'Cross-functional Collaboration', 'Agile/Scrum Methodologies', 'Project Management', 'Technical Writing & Documentation', 'Public Speaking & Presentation'], 'level': 'advanced'}], 'experience': [{'company': 'TechCorp Solutions', 'position': 'Senior Backend AI Engineer', 'startDate': '2022-01', 'endDate': 'Present', 'highlights': ['Led development of enterprise-scale AI-powered recommendation system serving 10M+ daily active users.', 'Architected and implemented microservices-based recommendation engine using Python, FastAPI, and TensorFlow, resulting in 35% increase in user engagement and $2.3M additional quarterly revenue.', 'Designed and deployed real-time machine learning pipeline processing 500K+ events per second using Apache Kafka, Apache Beam, and Google Cloud Dataflow.', 'Optimized model inference latency from 200ms to 45ms through implementation of model quantization, caching strategies, and deployment on GPU-accelerated Kubernetes clusters.', 'Established MLOps practices including automated model retraining, A/B testing framework, and continuous monitoring, reducing model deployment time from 2 weeks to 2 hours.', 'Developed ensemble learning models using XGBoost and neural networks, achieving 94% precision and 97% recall in fraud detection.', 'Implemented real-time feature engineering pipeline using Apache Spark Streaming and Redis, processing 1M+ transactions per minute.', 'Created explainable AI dashboard using SHAP and LIME, enabling compliance with regulatory requirements and improving model interpretability for business stakeholders.', 'Led team of 6 backend engineers and 2 ML engineers, conducting code reviews, architectural decisions, and technical roadmap planning.', 'Mentored junior engineers on best practices in distributed systems design, machine learning engineering, and cloud-native development.'], 'technologies': ['Python', 'FastAPI', 'TensorFlow', 'Apache Kafka', 'Apache Beam', 'Google Cloud Dataflow', 'XGBoost', 'Neural Networks', 'Apache Spark Streaming', 'Redis', 'SHAP', 'LIME', 'Kubernetes']}, {'company': 'DataFlow Inc.', 'position': 'Backend AI Engineer', 'startDate': '2020-03', 'endDate': '2021-12', 'highlights': ['Developed conversational AI platform for customer support automation.', 'Built NLP pipeline using BERT and GPT-2 models for intent classification and response generation, handling 100K+ customer queries daily.', 'Implemented multi-language support using transformer models, expanding platform reach to 15 countries.', 'Created scalable backend architecture using Django, PostgreSQL, and Redis, supporting 99.9% uptime with auto-scaling capabilities.', 'Integrated platform with existing CRM systems via REST APIs and webhooks, reducing customer response time by 60%.', 'Developed CNN-based defect detection models using PyTorch and OpenCV, achieving 98% accuracy in manufacturing quality assessment.', 'Implemented edge computing deployment using NVIDIA Jetson and TensorRT, enabling real-time inference on production lines.', 'Created data pipeline for continuous model improvement using Apache Airflow and automated data labeling tools.'], 'technologies': ['BERT', 'GPT-2', 'Transformers', 'Django', 'PostgreSQL', 'Redis', 'REST APIs', 'PyTorch', 'OpenCV', 'NVIDIA Jetson', 'TensorRT', 'Apache Airflow']}, {'company': 'InnovateLabs', 'position': 'Machine Learning Engineer', 'startDate': '2018-06', 'endDate': '2020-02', 'highlights': ['Built predictive analytics platform for supply chain optimization.', 'Developed time series forecasting models using LSTM networks and Prophet, improving demand prediction accuracy by 25%.', 'Implemented distributed training using Horovod and TensorFlow, reducing model training time from 8 hours to 2 hours.', 'Created RESTful APIs using Flask and deployed models using Docker containers on AWS ECS.', 'Established data versioning and experiment tracking using DVC and MLflow.', 'Implemented collaborative filtering and content-based filtering algorithms using Spark MLlib and Scala.', 'Built real-time recommendation API serving 50K+ requests per minute with sub-100ms latency.', 'Designed A/B testing framework for model evaluation and business impact measurement.'], 'technologies': ['LSTM', 'Prophet', 'Horovod', 'TensorFlow', 'Flask', 'Docker', 'AWS ECS', 'DVC', 'MLflow', 'Spark MLlib', 'Scala']}, {'company': 'CloudTech Systems', 'position': 'Software Engineer', 'startDate': '2016-08', 'endDate': '2018-05', 'highlights': ['Contributed to development of distributed data processing platform.', 'Implemented microservices using Java Spring Boot and deployed on Kubernetes clusters.', 'Developed data ingestion pipelines using Apache Kafka and Apache Storm for real-time analytics.', 'Optimized database queries and implemented caching strategies, improving application performance by 40%.', 'Collaborated with DevOps team to establish CI/CD pipelines and infrastructure automation.'], 'technologies': ['Java', 'Spring Boot', 'Kubernetes', 'Apache Kafka', 'Apache Storm']}], 'education': [{'institution': 'Stanford University', 'degree': 'Master of Science', 'field': 'Computer Science (Specialization: Artificial Intelligence and Machine Learning)', 'graduationDate': '2016', 'gpa': 3.8}, {'institution': 'UC Berkeley', 'degree': 'Bachelor of Science', 'field': 'Computer Engineering', 'graduationDate': '2014', 'gpa': None}], 'certifications': [{'name': 'AWS Certified Solutions Architect - Professional', 'issuer': None, 'date': '2023', 'validUntil': None}, {'name': 'Google Cloud Professional Machine Learning Engineer', 'issuer': None, 'date': '2023', 'validUntil': None}, {'name': 'Certified Kubernetes Administrator (CKA)', 'issuer': None, 'date': '2022', 'validUntil': None}, {'name': 'TensorFlow Developer Certificate', 'issuer': None, 'date': '2021', 'validUntil': None}, {'name': 'MongoDB Certified Developer', 'issuer': None, 'date': '2020', 'validUntil': None}], 'publications': [{'title': 'Efficient Neural Architecture Search for Edge Computing', 'publisher': 'ICML', 'date': '2023', 'url': ''}, {'title': 'Scalable Real-time Recommendation Systems Using Graph Neural Networks', 'publisher': 'IEEE BigData', 'date': '2022', 'url': ''}, {'title': 'Federated Learning for Privacy-Preserving Healthcare Analytics', 'publisher': 'NeurIPS Workshop', 'date': '2021', 'url': ''}]}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_json(obj, indent=0):\n",
        "    lines = []\n",
        "    spacer = '  ' * indent\n",
        "\n",
        "    if isinstance(obj, dict):\n",
        "        for key, value in obj.items():\n",
        "            key_title = key.replace(\"_\", \" \").capitalize()\n",
        "            if isinstance(value, (dict, list)):\n",
        "                lines.append(f\"{spacer}### {key_title}\")\n",
        "                lines.append(\"\")\n",
        "                lines.extend(flatten_json(value, indent + 1))\n",
        "            else:\n",
        "                lines.append(f\"{spacer}- {key_title}: {value}\")\n",
        "    elif isinstance(obj, list):\n",
        "        for item in obj:\n",
        "            if isinstance(item, (dict, list)):\n",
        "                lines.extend(flatten_json(item, indent))  # No \"### Item\"\n",
        "                lines.append(\"\")\n",
        "            else:\n",
        "                lines.append(f\"{spacer}- {item}\")\n",
        "    else:\n",
        "        lines.append(f\"{spacer}- {obj}\")\n",
        "    return lines\n",
        "\n",
        "\n",
        "def resume_json_to_text(data):\n",
        "    lines = []\n",
        "    for section_key, section_value in data.items():\n",
        "        title = section_key.replace(\"_\", \" \").capitalize()\n",
        "        lines.append(f\"## {title}\")\n",
        "        lines.append(\"\")  # blank line after section title\n",
        "        lines.extend(flatten_json(section_value, indent=1))\n",
        "        lines.append(\"\")  # blank line between sections\n",
        "    return \"\\n\".join(lines)\n"
      ],
      "metadata": {
        "id": "6Y2bNLF6_5-M"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resume_text = resume_json_to_text(parsed_data.data)\n",
        "print(resume_text)"
      ],
      "metadata": {
        "id": "3GwkG5DXZjlj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97fb3c9a-73a1-4d17-e512-c32d2d7097de"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Basics\n",
            "\n",
            "  - Name: Alexandra Chen\n",
            "  - Email: alexandra.chen@email.com\n",
            "  - Phone: +1 (555) 123-4567\n",
            "  ### Location\n",
            "\n",
            "    - City: San Francisco\n",
            "    - Region: CA\n",
            "    - Country: USA\n",
            "  ### Profiles\n",
            "\n",
            "    - Network: LinkedIn\n",
            "    - Url: https://linkedin.com/in/alexandrachen\n",
            "\n",
            "    - Network: GitHub\n",
            "    - Url: https://github.com/alexchen-dev\n",
            "\n",
            "  - Summary: Accomplished Senior Backend AI Engineer with 8+ years of experience designing and implementing scalable, high-performance backend systems and AI/ML solutions. Proven track record of leading cross-functional teams to deliver enterprise-grade applications serving millions of users. Expertise in distributed systems, microservices architecture, machine learning pipelines, and cloud-native technologies. Passionate about leveraging cutting-edge AI technologies to solve complex business problems while maintaining system reliability and performance.\n",
            "\n",
            "## Skills\n",
            "\n",
            "  - Category: Programming Languages\n",
            "  ### Keywords\n",
            "\n",
            "    - Python\n",
            "    - Java\n",
            "    - Scala\n",
            "    - Go\n",
            "    - C++\n",
            "    - JavaScript/TypeScript\n",
            "    - SQL\n",
            "    - R\n",
            "  - Level: expert\n",
            "\n",
            "  - Category: AI/ML Technologies\n",
            "  ### Keywords\n",
            "\n",
            "    - TensorFlow\n",
            "    - PyTorch\n",
            "    - Scikit-learn\n",
            "    - Keras\n",
            "    - XGBoost\n",
            "    - LightGBM\n",
            "    - MLflow\n",
            "    - Kubeflow\n",
            "    - Apache Airflow\n",
            "    - DVC\n",
            "    - Weights & Biases\n",
            "    - TensorFlow Serving\n",
            "    - TorchServe\n",
            "    - ONNX Runtime\n",
            "    - Triton Inference Server\n",
            "    - Transformers\n",
            "    - BERT\n",
            "    - GPT\n",
            "    - spaCy\n",
            "    - NLTK\n",
            "    - Hugging Face\n",
            "    - OpenCV\n",
            "    - PIL\n",
            "    - Detectron2\n",
            "    - YOLO\n",
            "    - OpenAI Gym\n",
            "    - Stable Baselines3\n",
            "    - Ray RLlib\n",
            "  - Level: expert\n",
            "\n",
            "  - Category: Backend Technologies\n",
            "  ### Keywords\n",
            "\n",
            "    - Django\n",
            "    - FastAPI\n",
            "    - Flask\n",
            "    - Spring Boot\n",
            "    - Express.js\n",
            "    - Gin\n",
            "    - Echo\n",
            "    - PostgreSQL\n",
            "    - MongoDB\n",
            "    - Redis\n",
            "    - Cassandra\n",
            "    - ClickHouse\n",
            "    - Neo4j\n",
            "    - Apache Kafka\n",
            "    - RabbitMQ\n",
            "    - Amazon SQS\n",
            "    - Apache Pulsar\n",
            "    - Elasticsearch\n",
            "    - Apache Solr\n",
            "    - Amazon OpenSearch\n",
            "    - REST\n",
            "    - GraphQL\n",
            "    - gRPC\n",
            "    - WebSockets\n",
            "  - Level: expert\n",
            "\n",
            "  - Category: Cloud Platforms\n",
            "  ### Keywords\n",
            "\n",
            "    - AWS\n",
            "    - Google Cloud Platform\n",
            "    - Microsoft Azure\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: Container Technologies\n",
            "  ### Keywords\n",
            "\n",
            "    - Docker\n",
            "    - Kubernetes\n",
            "    - Helm\n",
            "    - Istio\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: Infrastructure as Code\n",
            "  ### Keywords\n",
            "\n",
            "    - Terraform\n",
            "    - CloudFormation\n",
            "    - Ansible\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: Monitoring\n",
            "  ### Keywords\n",
            "\n",
            "    - Prometheus\n",
            "    - Grafana\n",
            "    - ELK Stack\n",
            "    - Datadog\n",
            "    - New Relic\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: CI/CD\n",
            "  ### Keywords\n",
            "\n",
            "    - Jenkins\n",
            "    - GitLab CI\n",
            "    - GitHub Actions\n",
            "    - CircleCI\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: Data Engineering\n",
            "  ### Keywords\n",
            "\n",
            "    - Apache Spark\n",
            "    - Apache Beam\n",
            "    - Apache Flink\n",
            "    - Databricks\n",
            "    - Snowflake\n",
            "    - BigQuery\n",
            "    - Redshift\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: Languages\n",
            "  ### Keywords\n",
            "\n",
            "    - English (Native)\n",
            "    - Mandarin Chinese (Fluent)\n",
            "    - Spanish (Conversational)\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: Leadership & Soft Skills\n",
            "  ### Keywords\n",
            "\n",
            "    - Technical Team Leadership\n",
            "    - Cross-functional Collaboration\n",
            "    - Agile/Scrum Methodologies\n",
            "    - Project Management\n",
            "    - Technical Writing & Documentation\n",
            "    - Public Speaking & Presentation\n",
            "  - Level: advanced\n",
            "\n",
            "\n",
            "## Experience\n",
            "\n",
            "  - Company: TechCorp Solutions\n",
            "  - Position: Senior Backend AI Engineer\n",
            "  - Startdate: 2022-01\n",
            "  - Enddate: Present\n",
            "  ### Highlights\n",
            "\n",
            "    - Led development of enterprise-scale AI-powered recommendation system serving 10M+ daily active users.\n",
            "    - Architected and implemented microservices-based recommendation engine using Python, FastAPI, and TensorFlow, resulting in 35% increase in user engagement and $2.3M additional quarterly revenue.\n",
            "    - Designed and deployed real-time machine learning pipeline processing 500K+ events per second using Apache Kafka, Apache Beam, and Google Cloud Dataflow.\n",
            "    - Optimized model inference latency from 200ms to 45ms through implementation of model quantization, caching strategies, and deployment on GPU-accelerated Kubernetes clusters.\n",
            "    - Established MLOps practices including automated model retraining, A/B testing framework, and continuous monitoring, reducing model deployment time from 2 weeks to 2 hours.\n",
            "    - Developed ensemble learning models using XGBoost and neural networks, achieving 94% precision and 97% recall in fraud detection.\n",
            "    - Implemented real-time feature engineering pipeline using Apache Spark Streaming and Redis, processing 1M+ transactions per minute.\n",
            "    - Created explainable AI dashboard using SHAP and LIME, enabling compliance with regulatory requirements and improving model interpretability for business stakeholders.\n",
            "    - Led team of 6 backend engineers and 2 ML engineers, conducting code reviews, architectural decisions, and technical roadmap planning.\n",
            "    - Mentored junior engineers on best practices in distributed systems design, machine learning engineering, and cloud-native development.\n",
            "  ### Technologies\n",
            "\n",
            "    - Python\n",
            "    - FastAPI\n",
            "    - TensorFlow\n",
            "    - Apache Kafka\n",
            "    - Apache Beam\n",
            "    - Google Cloud Dataflow\n",
            "    - XGBoost\n",
            "    - Neural Networks\n",
            "    - Apache Spark Streaming\n",
            "    - Redis\n",
            "    - SHAP\n",
            "    - LIME\n",
            "    - Kubernetes\n",
            "\n",
            "  - Company: DataFlow Inc.\n",
            "  - Position: Backend AI Engineer\n",
            "  - Startdate: 2020-03\n",
            "  - Enddate: 2021-12\n",
            "  ### Highlights\n",
            "\n",
            "    - Developed conversational AI platform for customer support automation.\n",
            "    - Built NLP pipeline using BERT and GPT-2 models for intent classification and response generation, handling 100K+ customer queries daily.\n",
            "    - Implemented multi-language support using transformer models, expanding platform reach to 15 countries.\n",
            "    - Created scalable backend architecture using Django, PostgreSQL, and Redis, supporting 99.9% uptime with auto-scaling capabilities.\n",
            "    - Integrated platform with existing CRM systems via REST APIs and webhooks, reducing customer response time by 60%.\n",
            "    - Developed CNN-based defect detection models using PyTorch and OpenCV, achieving 98% accuracy in manufacturing quality assessment.\n",
            "    - Implemented edge computing deployment using NVIDIA Jetson and TensorRT, enabling real-time inference on production lines.\n",
            "    - Created data pipeline for continuous model improvement using Apache Airflow and automated data labeling tools.\n",
            "  ### Technologies\n",
            "\n",
            "    - BERT\n",
            "    - GPT-2\n",
            "    - Transformers\n",
            "    - Django\n",
            "    - PostgreSQL\n",
            "    - Redis\n",
            "    - REST APIs\n",
            "    - PyTorch\n",
            "    - OpenCV\n",
            "    - NVIDIA Jetson\n",
            "    - TensorRT\n",
            "    - Apache Airflow\n",
            "\n",
            "  - Company: InnovateLabs\n",
            "  - Position: Machine Learning Engineer\n",
            "  - Startdate: 2018-06\n",
            "  - Enddate: 2020-02\n",
            "  ### Highlights\n",
            "\n",
            "    - Built predictive analytics platform for supply chain optimization.\n",
            "    - Developed time series forecasting models using LSTM networks and Prophet, improving demand prediction accuracy by 25%.\n",
            "    - Implemented distributed training using Horovod and TensorFlow, reducing model training time from 8 hours to 2 hours.\n",
            "    - Created RESTful APIs using Flask and deployed models using Docker containers on AWS ECS.\n",
            "    - Established data versioning and experiment tracking using DVC and MLflow.\n",
            "    - Implemented collaborative filtering and content-based filtering algorithms using Spark MLlib and Scala.\n",
            "    - Built real-time recommendation API serving 50K+ requests per minute with sub-100ms latency.\n",
            "    - Designed A/B testing framework for model evaluation and business impact measurement.\n",
            "  ### Technologies\n",
            "\n",
            "    - LSTM\n",
            "    - Prophet\n",
            "    - Horovod\n",
            "    - TensorFlow\n",
            "    - Flask\n",
            "    - Docker\n",
            "    - AWS ECS\n",
            "    - DVC\n",
            "    - MLflow\n",
            "    - Spark MLlib\n",
            "    - Scala\n",
            "\n",
            "  - Company: CloudTech Systems\n",
            "  - Position: Software Engineer\n",
            "  - Startdate: 2016-08\n",
            "  - Enddate: 2018-05\n",
            "  ### Highlights\n",
            "\n",
            "    - Contributed to development of distributed data processing platform.\n",
            "    - Implemented microservices using Java Spring Boot and deployed on Kubernetes clusters.\n",
            "    - Developed data ingestion pipelines using Apache Kafka and Apache Storm for real-time analytics.\n",
            "    - Optimized database queries and implemented caching strategies, improving application performance by 40%.\n",
            "    - Collaborated with DevOps team to establish CI/CD pipelines and infrastructure automation.\n",
            "  ### Technologies\n",
            "\n",
            "    - Java\n",
            "    - Spring Boot\n",
            "    - Kubernetes\n",
            "    - Apache Kafka\n",
            "    - Apache Storm\n",
            "\n",
            "\n",
            "## Education\n",
            "\n",
            "  - Institution: Stanford University\n",
            "  - Degree: Master of Science\n",
            "  - Field: Computer Science (Specialization: Artificial Intelligence and Machine Learning)\n",
            "  - Graduationdate: 2016\n",
            "  - Gpa: 3.8\n",
            "\n",
            "  - Institution: UC Berkeley\n",
            "  - Degree: Bachelor of Science\n",
            "  - Field: Computer Engineering\n",
            "  - Graduationdate: 2014\n",
            "  - Gpa: None\n",
            "\n",
            "\n",
            "## Certifications\n",
            "\n",
            "  - Name: AWS Certified Solutions Architect - Professional\n",
            "  - Issuer: None\n",
            "  - Date: 2023\n",
            "  - Validuntil: None\n",
            "\n",
            "  - Name: Google Cloud Professional Machine Learning Engineer\n",
            "  - Issuer: None\n",
            "  - Date: 2023\n",
            "  - Validuntil: None\n",
            "\n",
            "  - Name: Certified Kubernetes Administrator (CKA)\n",
            "  - Issuer: None\n",
            "  - Date: 2022\n",
            "  - Validuntil: None\n",
            "\n",
            "  - Name: TensorFlow Developer Certificate\n",
            "  - Issuer: None\n",
            "  - Date: 2021\n",
            "  - Validuntil: None\n",
            "\n",
            "  - Name: MongoDB Certified Developer\n",
            "  - Issuer: None\n",
            "  - Date: 2020\n",
            "  - Validuntil: None\n",
            "\n",
            "\n",
            "## Publications\n",
            "\n",
            "  - Title: Efficient Neural Architecture Search for Edge Computing\n",
            "  - Publisher: ICML\n",
            "  - Date: 2023\n",
            "  - Url: \n",
            "\n",
            "  - Title: Scalable Real-time Recommendation Systems Using Graph Neural Networks\n",
            "  - Publisher: IEEE BigData\n",
            "  - Date: 2022\n",
            "  - Url: \n",
            "\n",
            "  - Title: Federated Learning for Privacy-Preserving Healthcare Analytics\n",
            "  - Publisher: NeurIPS Workshop\n",
            "  - Date: 2021\n",
            "  - Url: \n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core import Settings\n",
        "\n",
        "Settings.embed_model = HuggingFaceEmbedding(\n",
        "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
        ")"
      ],
      "metadata": {
        "id": "XBsoELT1fzkj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17aecce1-afe1-44db-bb02-7c8d20736c8f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.schema import Document\n",
        "from llama_index.core.node_parser import SentenceSplitter,SimpleNodeParser\n",
        "from llama_index.core import VectorStoreIndex\n",
        "import re\n",
        "\n",
        "\n",
        "def extract_sections(text):\n",
        "    # Find all top-level ## section headers and their positions\n",
        "    section_pattern = re.compile(r\"^(## .+)$\", re.MULTILINE)\n",
        "    matches = list(section_pattern.finditer(text))\n",
        "\n",
        "    chunks = {}\n",
        "    for i, match in enumerate(matches):\n",
        "        section_title = match.group(1).replace('## ', '').strip()\n",
        "        # Determine section start and end\n",
        "        section_start = match.end()\n",
        "        if i + 1 < len(matches):\n",
        "            section_end = matches[i + 1].start()\n",
        "        else:\n",
        "            section_end = len(text)\n",
        "        section_content = text[section_start:section_end].strip()\n",
        "        chunks[section_title] = section_content\n",
        "    return chunks\n",
        "\n",
        "\n",
        "\n",
        "sections = extract_sections(resume_text)\n",
        "for title, content in sections.items():\n",
        "    print(f\"\\n==== {title} ====\\n{content}\\n\")\n"
      ],
      "metadata": {
        "id": "n6gY5OW2xJB2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6869345c-2ee6-4e37-aa73-abf0ae41adfa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "==== Basics ====\n",
            "- Name: Alexandra Chen\n",
            "  - Email: alexandra.chen@email.com\n",
            "  - Phone: +1 (555) 123-4567\n",
            "  ### Location\n",
            "\n",
            "    - City: San Francisco\n",
            "    - Region: CA\n",
            "    - Country: USA\n",
            "  ### Profiles\n",
            "\n",
            "    - Network: LinkedIn\n",
            "    - Url: https://linkedin.com/in/alexandrachen\n",
            "\n",
            "    - Network: GitHub\n",
            "    - Url: https://github.com/alexchen-dev\n",
            "\n",
            "  - Summary: Accomplished Senior Backend AI Engineer with 8+ years of experience designing and implementing scalable, high-performance backend systems and AI/ML solutions. Proven track record of leading cross-functional teams to deliver enterprise-grade applications serving millions of users. Expertise in distributed systems, microservices architecture, machine learning pipelines, and cloud-native technologies. Passionate about leveraging cutting-edge AI technologies to solve complex business problems while maintaining system reliability and performance.\n",
            "\n",
            "\n",
            "==== Skills ====\n",
            "- Category: Programming Languages\n",
            "  ### Keywords\n",
            "\n",
            "    - Python\n",
            "    - Java\n",
            "    - Scala\n",
            "    - Go\n",
            "    - C++\n",
            "    - JavaScript/TypeScript\n",
            "    - SQL\n",
            "    - R\n",
            "  - Level: expert\n",
            "\n",
            "  - Category: AI/ML Technologies\n",
            "  ### Keywords\n",
            "\n",
            "    - TensorFlow\n",
            "    - PyTorch\n",
            "    - Scikit-learn\n",
            "    - Keras\n",
            "    - XGBoost\n",
            "    - LightGBM\n",
            "    - MLflow\n",
            "    - Kubeflow\n",
            "    - Apache Airflow\n",
            "    - DVC\n",
            "    - Weights & Biases\n",
            "    - TensorFlow Serving\n",
            "    - TorchServe\n",
            "    - ONNX Runtime\n",
            "    - Triton Inference Server\n",
            "    - Transformers\n",
            "    - BERT\n",
            "    - GPT\n",
            "    - spaCy\n",
            "    - NLTK\n",
            "    - Hugging Face\n",
            "    - OpenCV\n",
            "    - PIL\n",
            "    - Detectron2\n",
            "    - YOLO\n",
            "    - OpenAI Gym\n",
            "    - Stable Baselines3\n",
            "    - Ray RLlib\n",
            "  - Level: expert\n",
            "\n",
            "  - Category: Backend Technologies\n",
            "  ### Keywords\n",
            "\n",
            "    - Django\n",
            "    - FastAPI\n",
            "    - Flask\n",
            "    - Spring Boot\n",
            "    - Express.js\n",
            "    - Gin\n",
            "    - Echo\n",
            "    - PostgreSQL\n",
            "    - MongoDB\n",
            "    - Redis\n",
            "    - Cassandra\n",
            "    - ClickHouse\n",
            "    - Neo4j\n",
            "    - Apache Kafka\n",
            "    - RabbitMQ\n",
            "    - Amazon SQS\n",
            "    - Apache Pulsar\n",
            "    - Elasticsearch\n",
            "    - Apache Solr\n",
            "    - Amazon OpenSearch\n",
            "    - REST\n",
            "    - GraphQL\n",
            "    - gRPC\n",
            "    - WebSockets\n",
            "  - Level: expert\n",
            "\n",
            "  - Category: Cloud Platforms\n",
            "  ### Keywords\n",
            "\n",
            "    - AWS\n",
            "    - Google Cloud Platform\n",
            "    - Microsoft Azure\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: Container Technologies\n",
            "  ### Keywords\n",
            "\n",
            "    - Docker\n",
            "    - Kubernetes\n",
            "    - Helm\n",
            "    - Istio\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: Infrastructure as Code\n",
            "  ### Keywords\n",
            "\n",
            "    - Terraform\n",
            "    - CloudFormation\n",
            "    - Ansible\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: Monitoring\n",
            "  ### Keywords\n",
            "\n",
            "    - Prometheus\n",
            "    - Grafana\n",
            "    - ELK Stack\n",
            "    - Datadog\n",
            "    - New Relic\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: CI/CD\n",
            "  ### Keywords\n",
            "\n",
            "    - Jenkins\n",
            "    - GitLab CI\n",
            "    - GitHub Actions\n",
            "    - CircleCI\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: Data Engineering\n",
            "  ### Keywords\n",
            "\n",
            "    - Apache Spark\n",
            "    - Apache Beam\n",
            "    - Apache Flink\n",
            "    - Databricks\n",
            "    - Snowflake\n",
            "    - BigQuery\n",
            "    - Redshift\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: Languages\n",
            "  ### Keywords\n",
            "\n",
            "    - English (Native)\n",
            "    - Mandarin Chinese (Fluent)\n",
            "    - Spanish (Conversational)\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: Leadership & Soft Skills\n",
            "  ### Keywords\n",
            "\n",
            "    - Technical Team Leadership\n",
            "    - Cross-functional Collaboration\n",
            "    - Agile/Scrum Methodologies\n",
            "    - Project Management\n",
            "    - Technical Writing & Documentation\n",
            "    - Public Speaking & Presentation\n",
            "  - Level: advanced\n",
            "\n",
            "\n",
            "==== Experience ====\n",
            "- Company: TechCorp Solutions\n",
            "  - Position: Senior Backend AI Engineer\n",
            "  - Startdate: 2022-01\n",
            "  - Enddate: Present\n",
            "  ### Highlights\n",
            "\n",
            "    - Led development of enterprise-scale AI-powered recommendation system serving 10M+ daily active users.\n",
            "    - Architected and implemented microservices-based recommendation engine using Python, FastAPI, and TensorFlow, resulting in 35% increase in user engagement and $2.3M additional quarterly revenue.\n",
            "    - Designed and deployed real-time machine learning pipeline processing 500K+ events per second using Apache Kafka, Apache Beam, and Google Cloud Dataflow.\n",
            "    - Optimized model inference latency from 200ms to 45ms through implementation of model quantization, caching strategies, and deployment on GPU-accelerated Kubernetes clusters.\n",
            "    - Established MLOps practices including automated model retraining, A/B testing framework, and continuous monitoring, reducing model deployment time from 2 weeks to 2 hours.\n",
            "    - Developed ensemble learning models using XGBoost and neural networks, achieving 94% precision and 97% recall in fraud detection.\n",
            "    - Implemented real-time feature engineering pipeline using Apache Spark Streaming and Redis, processing 1M+ transactions per minute.\n",
            "    - Created explainable AI dashboard using SHAP and LIME, enabling compliance with regulatory requirements and improving model interpretability for business stakeholders.\n",
            "    - Led team of 6 backend engineers and 2 ML engineers, conducting code reviews, architectural decisions, and technical roadmap planning.\n",
            "    - Mentored junior engineers on best practices in distributed systems design, machine learning engineering, and cloud-native development.\n",
            "  ### Technologies\n",
            "\n",
            "    - Python\n",
            "    - FastAPI\n",
            "    - TensorFlow\n",
            "    - Apache Kafka\n",
            "    - Apache Beam\n",
            "    - Google Cloud Dataflow\n",
            "    - XGBoost\n",
            "    - Neural Networks\n",
            "    - Apache Spark Streaming\n",
            "    - Redis\n",
            "    - SHAP\n",
            "    - LIME\n",
            "    - Kubernetes\n",
            "\n",
            "  - Company: DataFlow Inc.\n",
            "  - Position: Backend AI Engineer\n",
            "  - Startdate: 2020-03\n",
            "  - Enddate: 2021-12\n",
            "  ### Highlights\n",
            "\n",
            "    - Developed conversational AI platform for customer support automation.\n",
            "    - Built NLP pipeline using BERT and GPT-2 models for intent classification and response generation, handling 100K+ customer queries daily.\n",
            "    - Implemented multi-language support using transformer models, expanding platform reach to 15 countries.\n",
            "    - Created scalable backend architecture using Django, PostgreSQL, and Redis, supporting 99.9% uptime with auto-scaling capabilities.\n",
            "    - Integrated platform with existing CRM systems via REST APIs and webhooks, reducing customer response time by 60%.\n",
            "    - Developed CNN-based defect detection models using PyTorch and OpenCV, achieving 98% accuracy in manufacturing quality assessment.\n",
            "    - Implemented edge computing deployment using NVIDIA Jetson and TensorRT, enabling real-time inference on production lines.\n",
            "    - Created data pipeline for continuous model improvement using Apache Airflow and automated data labeling tools.\n",
            "  ### Technologies\n",
            "\n",
            "    - BERT\n",
            "    - GPT-2\n",
            "    - Transformers\n",
            "    - Django\n",
            "    - PostgreSQL\n",
            "    - Redis\n",
            "    - REST APIs\n",
            "    - PyTorch\n",
            "    - OpenCV\n",
            "    - NVIDIA Jetson\n",
            "    - TensorRT\n",
            "    - Apache Airflow\n",
            "\n",
            "  - Company: InnovateLabs\n",
            "  - Position: Machine Learning Engineer\n",
            "  - Startdate: 2018-06\n",
            "  - Enddate: 2020-02\n",
            "  ### Highlights\n",
            "\n",
            "    - Built predictive analytics platform for supply chain optimization.\n",
            "    - Developed time series forecasting models using LSTM networks and Prophet, improving demand prediction accuracy by 25%.\n",
            "    - Implemented distributed training using Horovod and TensorFlow, reducing model training time from 8 hours to 2 hours.\n",
            "    - Created RESTful APIs using Flask and deployed models using Docker containers on AWS ECS.\n",
            "    - Established data versioning and experiment tracking using DVC and MLflow.\n",
            "    - Implemented collaborative filtering and content-based filtering algorithms using Spark MLlib and Scala.\n",
            "    - Built real-time recommendation API serving 50K+ requests per minute with sub-100ms latency.\n",
            "    - Designed A/B testing framework for model evaluation and business impact measurement.\n",
            "  ### Technologies\n",
            "\n",
            "    - LSTM\n",
            "    - Prophet\n",
            "    - Horovod\n",
            "    - TensorFlow\n",
            "    - Flask\n",
            "    - Docker\n",
            "    - AWS ECS\n",
            "    - DVC\n",
            "    - MLflow\n",
            "    - Spark MLlib\n",
            "    - Scala\n",
            "\n",
            "  - Company: CloudTech Systems\n",
            "  - Position: Software Engineer\n",
            "  - Startdate: 2016-08\n",
            "  - Enddate: 2018-05\n",
            "  ### Highlights\n",
            "\n",
            "    - Contributed to development of distributed data processing platform.\n",
            "    - Implemented microservices using Java Spring Boot and deployed on Kubernetes clusters.\n",
            "    - Developed data ingestion pipelines using Apache Kafka and Apache Storm for real-time analytics.\n",
            "    - Optimized database queries and implemented caching strategies, improving application performance by 40%.\n",
            "    - Collaborated with DevOps team to establish CI/CD pipelines and infrastructure automation.\n",
            "  ### Technologies\n",
            "\n",
            "    - Java\n",
            "    - Spring Boot\n",
            "    - Kubernetes\n",
            "    - Apache Kafka\n",
            "    - Apache Storm\n",
            "\n",
            "\n",
            "==== Education ====\n",
            "- Institution: Stanford University\n",
            "  - Degree: Master of Science\n",
            "  - Field: Computer Science (Specialization: Artificial Intelligence and Machine Learning)\n",
            "  - Graduationdate: 2016\n",
            "  - Gpa: 3.8\n",
            "\n",
            "  - Institution: UC Berkeley\n",
            "  - Degree: Bachelor of Science\n",
            "  - Field: Computer Engineering\n",
            "  - Graduationdate: 2014\n",
            "  - Gpa: None\n",
            "\n",
            "\n",
            "==== Certifications ====\n",
            "- Name: AWS Certified Solutions Architect - Professional\n",
            "  - Issuer: None\n",
            "  - Date: 2023\n",
            "  - Validuntil: None\n",
            "\n",
            "  - Name: Google Cloud Professional Machine Learning Engineer\n",
            "  - Issuer: None\n",
            "  - Date: 2023\n",
            "  - Validuntil: None\n",
            "\n",
            "  - Name: Certified Kubernetes Administrator (CKA)\n",
            "  - Issuer: None\n",
            "  - Date: 2022\n",
            "  - Validuntil: None\n",
            "\n",
            "  - Name: TensorFlow Developer Certificate\n",
            "  - Issuer: None\n",
            "  - Date: 2021\n",
            "  - Validuntil: None\n",
            "\n",
            "  - Name: MongoDB Certified Developer\n",
            "  - Issuer: None\n",
            "  - Date: 2020\n",
            "  - Validuntil: None\n",
            "\n",
            "\n",
            "==== Publications ====\n",
            "- Title: Efficient Neural Architecture Search for Edge Computing\n",
            "  - Publisher: ICML\n",
            "  - Date: 2023\n",
            "  - Url: \n",
            "\n",
            "  - Title: Scalable Real-time Recommendation Systems Using Graph Neural Networks\n",
            "  - Publisher: IEEE BigData\n",
            "  - Date: 2022\n",
            "  - Url: \n",
            "\n",
            "  - Title: Federated Learning for Privacy-Preserving Healthcare Analytics\n",
            "  - Publisher: NeurIPS Workshop\n",
            "  - Date: 2021\n",
            "  - Url:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core.schema import Document\n",
        "\n",
        "def create_nodes_with_custom_chunking(sections_dict):\n",
        "    all_nodes = []\n",
        "\n",
        "    for section_name, content in sections_dict.items():\n",
        "        section_length = len(content)\n",
        "        print(f\"{section_name} section: {section_length} characters\")\n",
        "\n",
        "        # Create section-specific parser\n",
        "        parser = SentenceSplitter(\n",
        "            chunk_size=section_length + 200,  # Section size + buffer\n",
        "            chunk_overlap=0,\n",
        "            chunking_tokenizer_fn=None\n",
        "        )\n",
        "\n",
        "        # Create document for this section\n",
        "        doc = Document(text=content, metadata={'section': section_name})\n",
        "\n",
        "        # Parse this section\n",
        "        section_nodes = parser.get_nodes_from_documents([doc])\n",
        "        all_nodes.extend(section_nodes)\n",
        "\n",
        "    return all_nodes\n",
        "\n",
        "# Use it\n",
        "nodes = create_nodes_with_custom_chunking(sections)\n",
        "#Visualize Node Data\n",
        "for idx,node in enumerate(nodes):\n",
        "    print(f\"\\n\\n---Node {idx+1}---\\n\\n\")\n",
        "    print(node.metadata)\n",
        "    print(node.text)"
      ],
      "metadata": {
        "id": "KRfX85zoqtgf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf74863f-dec2-4d5a-f582-76055a5dff2b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Basics section: 882 characters\n",
            "Skills section: 2383 characters\n",
            "Experience section: 5018 characters\n",
            "Education section: 326 characters\n",
            "Certifications section: 519 characters\n",
            "Publications section: 375 characters\n",
            "\n",
            "\n",
            "---Node 1---\n",
            "\n",
            "\n",
            "{'section': 'Basics'}\n",
            "- Name: Alexandra Chen\n",
            "  - Email: alexandra.chen@email.com\n",
            "  - Phone: +1 (555) 123-4567\n",
            "  ### Location\n",
            "\n",
            "    - City: San Francisco\n",
            "    - Region: CA\n",
            "    - Country: USA\n",
            "  ### Profiles\n",
            "\n",
            "    - Network: LinkedIn\n",
            "    - Url: https://linkedin.com/in/alexandrachen\n",
            "\n",
            "    - Network: GitHub\n",
            "    - Url: https://github.com/alexchen-dev\n",
            "\n",
            "  - Summary: Accomplished Senior Backend AI Engineer with 8+ years of experience designing and implementing scalable, high-performance backend systems and AI/ML solutions. Proven track record of leading cross-functional teams to deliver enterprise-grade applications serving millions of users. Expertise in distributed systems, microservices architecture, machine learning pipelines, and cloud-native technologies. Passionate about leveraging cutting-edge AI technologies to solve complex business problems while maintaining system reliability and performance.\n",
            "\n",
            "\n",
            "---Node 2---\n",
            "\n",
            "\n",
            "{'section': 'Skills'}\n",
            "- Category: Programming Languages\n",
            "  ### Keywords\n",
            "\n",
            "    - Python\n",
            "    - Java\n",
            "    - Scala\n",
            "    - Go\n",
            "    - C++\n",
            "    - JavaScript/TypeScript\n",
            "    - SQL\n",
            "    - R\n",
            "  - Level: expert\n",
            "\n",
            "  - Category: AI/ML Technologies\n",
            "  ### Keywords\n",
            "\n",
            "    - TensorFlow\n",
            "    - PyTorch\n",
            "    - Scikit-learn\n",
            "    - Keras\n",
            "    - XGBoost\n",
            "    - LightGBM\n",
            "    - MLflow\n",
            "    - Kubeflow\n",
            "    - Apache Airflow\n",
            "    - DVC\n",
            "    - Weights & Biases\n",
            "    - TensorFlow Serving\n",
            "    - TorchServe\n",
            "    - ONNX Runtime\n",
            "    - Triton Inference Server\n",
            "    - Transformers\n",
            "    - BERT\n",
            "    - GPT\n",
            "    - spaCy\n",
            "    - NLTK\n",
            "    - Hugging Face\n",
            "    - OpenCV\n",
            "    - PIL\n",
            "    - Detectron2\n",
            "    - YOLO\n",
            "    - OpenAI Gym\n",
            "    - Stable Baselines3\n",
            "    - Ray RLlib\n",
            "  - Level: expert\n",
            "\n",
            "  - Category: Backend Technologies\n",
            "  ### Keywords\n",
            "\n",
            "    - Django\n",
            "    - FastAPI\n",
            "    - Flask\n",
            "    - Spring Boot\n",
            "    - Express.js\n",
            "    - Gin\n",
            "    - Echo\n",
            "    - PostgreSQL\n",
            "    - MongoDB\n",
            "    - Redis\n",
            "    - Cassandra\n",
            "    - ClickHouse\n",
            "    - Neo4j\n",
            "    - Apache Kafka\n",
            "    - RabbitMQ\n",
            "    - Amazon SQS\n",
            "    - Apache Pulsar\n",
            "    - Elasticsearch\n",
            "    - Apache Solr\n",
            "    - Amazon OpenSearch\n",
            "    - REST\n",
            "    - GraphQL\n",
            "    - gRPC\n",
            "    - WebSockets\n",
            "  - Level: expert\n",
            "\n",
            "  - Category: Cloud Platforms\n",
            "  ### Keywords\n",
            "\n",
            "    - AWS\n",
            "    - Google Cloud Platform\n",
            "    - Microsoft Azure\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: Container Technologies\n",
            "  ### Keywords\n",
            "\n",
            "    - Docker\n",
            "    - Kubernetes\n",
            "    - Helm\n",
            "    - Istio\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: Infrastructure as Code\n",
            "  ### Keywords\n",
            "\n",
            "    - Terraform\n",
            "    - CloudFormation\n",
            "    - Ansible\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: Monitoring\n",
            "  ### Keywords\n",
            "\n",
            "    - Prometheus\n",
            "    - Grafana\n",
            "    - ELK Stack\n",
            "    - Datadog\n",
            "    - New Relic\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: CI/CD\n",
            "  ### Keywords\n",
            "\n",
            "    - Jenkins\n",
            "    - GitLab CI\n",
            "    - GitHub Actions\n",
            "    - CircleCI\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: Data Engineering\n",
            "  ### Keywords\n",
            "\n",
            "    - Apache Spark\n",
            "    - Apache Beam\n",
            "    - Apache Flink\n",
            "    - Databricks\n",
            "    - Snowflake\n",
            "    - BigQuery\n",
            "    - Redshift\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: Languages\n",
            "  ### Keywords\n",
            "\n",
            "    - English (Native)\n",
            "    - Mandarin Chinese (Fluent)\n",
            "    - Spanish (Conversational)\n",
            "  - Level: advanced\n",
            "\n",
            "  - Category: Leadership & Soft Skills\n",
            "  ### Keywords\n",
            "\n",
            "    - Technical Team Leadership\n",
            "    - Cross-functional Collaboration\n",
            "    - Agile/Scrum Methodologies\n",
            "    - Project Management\n",
            "    - Technical Writing & Documentation\n",
            "    - Public Speaking & Presentation\n",
            "  - Level: advanced\n",
            "\n",
            "\n",
            "---Node 3---\n",
            "\n",
            "\n",
            "{'section': 'Experience'}\n",
            "- Company: TechCorp Solutions\n",
            "  - Position: Senior Backend AI Engineer\n",
            "  - Startdate: 2022-01\n",
            "  - Enddate: Present\n",
            "  ### Highlights\n",
            "\n",
            "    - Led development of enterprise-scale AI-powered recommendation system serving 10M+ daily active users.\n",
            "    - Architected and implemented microservices-based recommendation engine using Python, FastAPI, and TensorFlow, resulting in 35% increase in user engagement and $2.3M additional quarterly revenue.\n",
            "    - Designed and deployed real-time machine learning pipeline processing 500K+ events per second using Apache Kafka, Apache Beam, and Google Cloud Dataflow.\n",
            "    - Optimized model inference latency from 200ms to 45ms through implementation of model quantization, caching strategies, and deployment on GPU-accelerated Kubernetes clusters.\n",
            "    - Established MLOps practices including automated model retraining, A/B testing framework, and continuous monitoring, reducing model deployment time from 2 weeks to 2 hours.\n",
            "    - Developed ensemble learning models using XGBoost and neural networks, achieving 94% precision and 97% recall in fraud detection.\n",
            "    - Implemented real-time feature engineering pipeline using Apache Spark Streaming and Redis, processing 1M+ transactions per minute.\n",
            "    - Created explainable AI dashboard using SHAP and LIME, enabling compliance with regulatory requirements and improving model interpretability for business stakeholders.\n",
            "    - Led team of 6 backend engineers and 2 ML engineers, conducting code reviews, architectural decisions, and technical roadmap planning.\n",
            "    - Mentored junior engineers on best practices in distributed systems design, machine learning engineering, and cloud-native development.\n",
            "  ### Technologies\n",
            "\n",
            "    - Python\n",
            "    - FastAPI\n",
            "    - TensorFlow\n",
            "    - Apache Kafka\n",
            "    - Apache Beam\n",
            "    - Google Cloud Dataflow\n",
            "    - XGBoost\n",
            "    - Neural Networks\n",
            "    - Apache Spark Streaming\n",
            "    - Redis\n",
            "    - SHAP\n",
            "    - LIME\n",
            "    - Kubernetes\n",
            "\n",
            "  - Company: DataFlow Inc.\n",
            "  - Position: Backend AI Engineer\n",
            "  - Startdate: 2020-03\n",
            "  - Enddate: 2021-12\n",
            "  ### Highlights\n",
            "\n",
            "    - Developed conversational AI platform for customer support automation.\n",
            "    - Built NLP pipeline using BERT and GPT-2 models for intent classification and response generation, handling 100K+ customer queries daily.\n",
            "    - Implemented multi-language support using transformer models, expanding platform reach to 15 countries.\n",
            "    - Created scalable backend architecture using Django, PostgreSQL, and Redis, supporting 99.9% uptime with auto-scaling capabilities.\n",
            "    - Integrated platform with existing CRM systems via REST APIs and webhooks, reducing customer response time by 60%.\n",
            "    - Developed CNN-based defect detection models using PyTorch and OpenCV, achieving 98% accuracy in manufacturing quality assessment.\n",
            "    - Implemented edge computing deployment using NVIDIA Jetson and TensorRT, enabling real-time inference on production lines.\n",
            "    - Created data pipeline for continuous model improvement using Apache Airflow and automated data labeling tools.\n",
            "  ### Technologies\n",
            "\n",
            "    - BERT\n",
            "    - GPT-2\n",
            "    - Transformers\n",
            "    - Django\n",
            "    - PostgreSQL\n",
            "    - Redis\n",
            "    - REST APIs\n",
            "    - PyTorch\n",
            "    - OpenCV\n",
            "    - NVIDIA Jetson\n",
            "    - TensorRT\n",
            "    - Apache Airflow\n",
            "\n",
            "  - Company: InnovateLabs\n",
            "  - Position: Machine Learning Engineer\n",
            "  - Startdate: 2018-06\n",
            "  - Enddate: 2020-02\n",
            "  ### Highlights\n",
            "\n",
            "    - Built predictive analytics platform for supply chain optimization.\n",
            "    - Developed time series forecasting models using LSTM networks and Prophet, improving demand prediction accuracy by 25%.\n",
            "    - Implemented distributed training using Horovod and TensorFlow, reducing model training time from 8 hours to 2 hours.\n",
            "    - Created RESTful APIs using Flask and deployed models using Docker containers on AWS ECS.\n",
            "    - Established data versioning and experiment tracking using DVC and MLflow.\n",
            "    - Implemented collaborative filtering and content-based filtering algorithms using Spark MLlib and Scala.\n",
            "    - Built real-time recommendation API serving 50K+ requests per minute with sub-100ms latency.\n",
            "    - Designed A/B testing framework for model evaluation and business impact measurement.\n",
            "  ### Technologies\n",
            "\n",
            "    - LSTM\n",
            "    - Prophet\n",
            "    - Horovod\n",
            "    - TensorFlow\n",
            "    - Flask\n",
            "    - Docker\n",
            "    - AWS ECS\n",
            "    - DVC\n",
            "    - MLflow\n",
            "    - Spark MLlib\n",
            "    - Scala\n",
            "\n",
            "  - Company: CloudTech Systems\n",
            "  - Position: Software Engineer\n",
            "  - Startdate: 2016-08\n",
            "  - Enddate: 2018-05\n",
            "  ### Highlights\n",
            "\n",
            "    - Contributed to development of distributed data processing platform.\n",
            "    - Implemented microservices using Java Spring Boot and deployed on Kubernetes clusters.\n",
            "    - Developed data ingestion pipelines using Apache Kafka and Apache Storm for real-time analytics.\n",
            "    - Optimized database queries and implemented caching strategies, improving application performance by 40%.\n",
            "    - Collaborated with DevOps team to establish CI/CD pipelines and infrastructure automation.\n",
            "  ### Technologies\n",
            "\n",
            "    - Java\n",
            "    - Spring Boot\n",
            "    - Kubernetes\n",
            "    - Apache Kafka\n",
            "    - Apache Storm\n",
            "\n",
            "\n",
            "---Node 4---\n",
            "\n",
            "\n",
            "{'section': 'Education'}\n",
            "- Institution: Stanford University\n",
            "  - Degree: Master of Science\n",
            "  - Field: Computer Science (Specialization: Artificial Intelligence and Machine Learning)\n",
            "  - Graduationdate: 2016\n",
            "  - Gpa: 3.8\n",
            "\n",
            "  - Institution: UC Berkeley\n",
            "  - Degree: Bachelor of Science\n",
            "  - Field: Computer Engineering\n",
            "  - Graduationdate: 2014\n",
            "  - Gpa: None\n",
            "\n",
            "\n",
            "---Node 5---\n",
            "\n",
            "\n",
            "{'section': 'Certifications'}\n",
            "- Name: AWS Certified Solutions Architect - Professional\n",
            "  - Issuer: None\n",
            "  - Date: 2023\n",
            "  - Validuntil: None\n",
            "\n",
            "  - Name: Google Cloud Professional Machine Learning Engineer\n",
            "  - Issuer: None\n",
            "  - Date: 2023\n",
            "  - Validuntil: None\n",
            "\n",
            "  - Name: Certified Kubernetes Administrator (CKA)\n",
            "  - Issuer: None\n",
            "  - Date: 2022\n",
            "  - Validuntil: None\n",
            "\n",
            "  - Name: TensorFlow Developer Certificate\n",
            "  - Issuer: None\n",
            "  - Date: 2021\n",
            "  - Validuntil: None\n",
            "\n",
            "  - Name: MongoDB Certified Developer\n",
            "  - Issuer: None\n",
            "  - Date: 2020\n",
            "  - Validuntil: None\n",
            "\n",
            "\n",
            "---Node 6---\n",
            "\n",
            "\n",
            "{'section': 'Publications'}\n",
            "- Title: Efficient Neural Architecture Search for Edge Computing\n",
            "  - Publisher: ICML\n",
            "  - Date: 2023\n",
            "  - Url: \n",
            "\n",
            "  - Title: Scalable Real-time Recommendation Systems Using Graph Neural Networks\n",
            "  - Publisher: IEEE BigData\n",
            "  - Date: 2022\n",
            "  - Url: \n",
            "\n",
            "  - Title: Federated Learning for Privacy-Preserving Healthcare Analytics\n",
            "  - Publisher: NeurIPS Workshop\n",
            "  - Date: 2021\n",
            "  - Url:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import VectorStoreIndex\n",
        "\n",
        "# Use the nodes from custom parsing\n",
        "index = VectorStoreIndex(nodes) ##Index from nodes\n",
        "index.storage_context.persist(persist_dir=\"resume_index\")\n"
      ],
      "metadata": {
        "id": "ipnGFqjQ5bcT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4a120ce-e601-432d-a68e-51fd5d7738eb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py:1750: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
            "  return forward_call(*args, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic index information\n",
        "print(f\"Index type: {type(index)}\")\n",
        "print(f\"Number of nodes in index: {len(index.docstore.docs)}\")\n",
        "print(f\"Index ID: {index.index_id}\")\n"
      ],
      "metadata": {
        "id": "BUF3b1PA0zJx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "591d7fac-01f7-4ca5-db77-be2de7bef132"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index type: <class 'llama_index.core.indices.vector_store.base.VectorStoreIndex'>\n",
            "Number of nodes in index: 6\n",
            "Index ID: 79b38e08-0167-4e28-b2c5-fc6fd72f2df9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_index_contents(index):\n",
        "    \"\"\"Comprehensive analysis of index contents\"\"\"\n",
        "\n",
        "    print(\"=== INDEX ANALYSIS ===\\n\")\n",
        "\n",
        "    # Basic stats\n",
        "    total_nodes = len(index.docstore.docs)\n",
        "    total_chars = sum(len(node.text) for node in index.docstore.docs.values())\n",
        "\n",
        "    print(f\"Total nodes: {total_nodes}\")\n",
        "    print(f\"Total characters: {total_chars:,}\")\n",
        "    print(f\"Average chars per node: {total_chars/total_nodes:.0f}\")\n",
        "\n",
        "    # Section breakdown\n",
        "    section_stats = {}\n",
        "    for node in index.docstore.docs.values():\n",
        "        section = node.metadata.get('section', 'Unknown')\n",
        "        if section not in section_stats:\n",
        "            section_stats[section] = {'count': 0, 'chars': 0}\n",
        "        section_stats[section]['count'] += 1\n",
        "        section_stats[section]['chars'] += len(node.text)\n",
        "\n",
        "    print(\"\\n=== BY SECTION ===\")\n",
        "    for section, stats in section_stats.items():\n",
        "        print(f\"{section}:\")\n",
        "        print(f\"  Nodes: {stats['count']}\")\n",
        "        print(f\"  Characters: {stats['chars']:,}\")\n",
        "        print(f\"  Avg per node: {stats['chars']/stats['count']:.0f}\")\n",
        "\n",
        "    return section_stats\n",
        "\n",
        "# Run analysis\n",
        "stats = analyze_index_contents(index)\n"
      ],
      "metadata": {
        "id": "hzb__iUx02Uv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39df4667-5cd8-4176-9ba9-297ca59846bf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== INDEX ANALYSIS ===\n",
            "\n",
            "Total nodes: 6\n",
            "Total characters: 9,503\n",
            "Average chars per node: 1584\n",
            "\n",
            "=== BY SECTION ===\n",
            "Basics:\n",
            "  Nodes: 1\n",
            "  Characters: 882\n",
            "  Avg per node: 882\n",
            "Skills:\n",
            "  Nodes: 1\n",
            "  Characters: 2,383\n",
            "  Avg per node: 2383\n",
            "Experience:\n",
            "  Nodes: 1\n",
            "  Characters: 5,018\n",
            "  Avg per node: 5018\n",
            "Education:\n",
            "  Nodes: 1\n",
            "  Characters: 326\n",
            "  Avg per node: 326\n",
            "Certifications:\n",
            "  Nodes: 1\n",
            "  Characters: 519\n",
            "  Avg per node: 519\n",
            "Publications:\n",
            "  Nodes: 1\n",
            "  Characters: 375\n",
            "  Avg per node: 375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "\n",
        "# Load the persisted index\n",
        "storage_context = StorageContext.from_defaults(persist_dir=\"resume_index\")\n",
        "loaded_index = load_index_from_storage(storage_context)\n",
        "\n",
        "# Verify it loaded correctly\n",
        "print(f\"Loaded index has {len(loaded_index.docstore.docs)} nodes\")\n",
        "\n",
        "# Compare with original\n",
        "print(f\"Original had {len(index.docstore.docs)} nodes\")\n",
        "print(f\"Match: {len(loaded_index.docstore.docs) == len(index.docstore.docs)}\")\n"
      ],
      "metadata": {
        "id": "RBfATwjW1Bjr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e47a0a2c-38dd-441f-815b-ad23f875094c"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading llama_index.core.storage.kvstore.simple_kvstore from resume_index/docstore.json.\n",
            "Loading llama_index.core.storage.kvstore.simple_kvstore from resume_index/index_store.json.\n",
            "Loaded index has 6 nodes\n",
            "Original had 6 nodes\n",
            "Match: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check what was persisted\n",
        "persist_dir = \"resume_index\"\n",
        "if os.path.exists(persist_dir):\n",
        "    files = os.listdir(persist_dir)\n",
        "    print(f\"Files in {persist_dir}:\")\n",
        "    for file in files:\n",
        "        file_path = os.path.join(persist_dir, file)\n",
        "        size = os.path.getsize(file_path)\n",
        "        print(f\"  {file} ({size} bytes)\")\n"
      ],
      "metadata": {
        "id": "op56wyF01Bl8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "257ff534-5d80-4f1a-b422-18fd887baf4e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in resume_index:\n",
            "  graph_store.json (18 bytes)\n",
            "  default__vector_store.json (52876 bytes)\n",
            "  image__vector_store.json (72 bytes)\n",
            "  docstore.json (16187 bytes)\n",
            "  index_store.json (751 bytes)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See all node IDs\n",
        "node_ids = list(index.docstore.docs.keys())\n",
        "print(f\"Node IDs: {node_ids[:5]}...\")  # Show first 5\n",
        "\n",
        "# Examine individual nodes\n",
        "for i, node_id in enumerate(node_ids):  # Show first 3 nodes\n",
        "    node = index.docstore.docs[node_id]\n",
        "    print(f\"\\n--- Node {i+1} ---\")\n",
        "    print(f\"Node ID: {node_id}\")\n",
        "    print(f\"Metadata: {node.metadata}\")\n",
        "    print(f\"Text preview: {node.text[:200]}...\")  # First 200 chars\n",
        "    print(f\"Text length: {len(node.text)} characters\")\n"
      ],
      "metadata": {
        "id": "wUEwAJyN4CTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9af5803e-9ee4-4724-ac0d-e3177af71e7e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node IDs: ['b49e6320-85fd-45a9-80e5-9017d9fda27d', 'd9ab67a8-d6cc-4d36-84fc-530ad80e8aa5', '9eb674be-6c9e-43fe-b462-eb9626b27af0', 'a6dce4d3-159e-4f55-8a9c-b6f5dbe0a88f', 'f2a4e0c6-997d-434c-89aa-f6b407d1e4d8']...\n",
            "\n",
            "--- Node 1 ---\n",
            "Node ID: b49e6320-85fd-45a9-80e5-9017d9fda27d\n",
            "Metadata: {'section': 'Basics'}\n",
            "Text preview: - Name: Alexandra Chen\n",
            "  - Email: alexandra.chen@email.com\n",
            "  - Phone: +1 (555) 123-4567\n",
            "  ### Location\n",
            "\n",
            "    - City: San Francisco\n",
            "    - Region: CA\n",
            "    - Country: USA\n",
            "  ### Profiles\n",
            "\n",
            "    - Network: Lin...\n",
            "Text length: 882 characters\n",
            "\n",
            "--- Node 2 ---\n",
            "Node ID: d9ab67a8-d6cc-4d36-84fc-530ad80e8aa5\n",
            "Metadata: {'section': 'Skills'}\n",
            "Text preview: - Category: Programming Languages\n",
            "  ### Keywords\n",
            "\n",
            "    - Python\n",
            "    - Java\n",
            "    - Scala\n",
            "    - Go\n",
            "    - C++\n",
            "    - JavaScript/TypeScript\n",
            "    - SQL\n",
            "    - R\n",
            "  - Level: expert\n",
            "\n",
            "  - Category: AI/ML Technologi...\n",
            "Text length: 2383 characters\n",
            "\n",
            "--- Node 3 ---\n",
            "Node ID: 9eb674be-6c9e-43fe-b462-eb9626b27af0\n",
            "Metadata: {'section': 'Experience'}\n",
            "Text preview: - Company: TechCorp Solutions\n",
            "  - Position: Senior Backend AI Engineer\n",
            "  - Startdate: 2022-01\n",
            "  - Enddate: Present\n",
            "  ### Highlights\n",
            "\n",
            "    - Led development of enterprise-scale AI-powered recommendation...\n",
            "Text length: 5018 characters\n",
            "\n",
            "--- Node 4 ---\n",
            "Node ID: a6dce4d3-159e-4f55-8a9c-b6f5dbe0a88f\n",
            "Metadata: {'section': 'Education'}\n",
            "Text preview: - Institution: Stanford University\n",
            "  - Degree: Master of Science\n",
            "  - Field: Computer Science (Specialization: Artificial Intelligence and Machine Learning)\n",
            "  - Graduationdate: 2016\n",
            "  - Gpa: 3.8\n",
            "\n",
            "  - I...\n",
            "Text length: 326 characters\n",
            "\n",
            "--- Node 5 ---\n",
            "Node ID: f2a4e0c6-997d-434c-89aa-f6b407d1e4d8\n",
            "Metadata: {'section': 'Certifications'}\n",
            "Text preview: - Name: AWS Certified Solutions Architect - Professional\n",
            "  - Issuer: None\n",
            "  - Date: 2023\n",
            "  - Validuntil: None\n",
            "\n",
            "  - Name: Google Cloud Professional Machine Learning Engineer\n",
            "  - Issuer: None\n",
            "  - Date: ...\n",
            "Text length: 519 characters\n",
            "\n",
            "--- Node 6 ---\n",
            "Node ID: ac693fd1-d9f2-4ea6-9310-0fb5bdf18796\n",
            "Metadata: {'section': 'Publications'}\n",
            "Text preview: - Title: Efficient Neural Architecture Search for Edge Computing\n",
            "  - Publisher: ICML\n",
            "  - Date: 2023\n",
            "  - Url: \n",
            "\n",
            "  - Title: Scalable Real-time Recommendation Systems Using Graph Neural Networks\n",
            "  - Publ...\n",
            "Text length: 375 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !huggingface-cli login"
      ],
      "metadata": {
        "id": "eIRGoOCv-zPr"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core import StorageContext, load_index_from_storage\n",
        "from llama_index.llms.huggingface import HuggingFaceLLM\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.memory import ChatMemoryBuffer\n",
        "from llama_index.core import get_response_synthesizer, PromptTemplate\n",
        "from transformers import BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "model_name = \"google/gemma-7b-it\"\n",
        "memory = ChatMemoryBuffer.from_defaults(token_limit=2048)\n",
        "\n",
        "def load_model(model_name):\n",
        "    \"\"\"Load HuggingFace model with 4-bit quantization\"\"\"\n",
        "    q4 = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "    )\n",
        "\n",
        "    llm = HuggingFaceLLM(\n",
        "        model_name=model_name,\n",
        "        tokenizer_name=model_name,\n",
        "        max_new_tokens=512,\n",
        "        model_kwargs={\"quantization_config\": q4},\n",
        "        generate_kwargs={'do_sample': False,},\n",
        "        device_map=\"auto\",\n",
        "    )\n",
        "    return llm\n",
        "\n",
        "def build_retriever(index):\n",
        "    \"\"\"Build enhanced retriever with more context\"\"\"\n",
        "    retriever = index.as_retriever(\n",
        "        similarity_top_k=6,\n",
        "    )\n",
        "    return retriever\n",
        "\n",
        "# Custom prompt template for enhanced reasoning\n",
        "CAREER_ADVISOR_PROMPT = PromptTemplate(\n",
        "    \"\"\"You are a professional career advisor. Analyze the candidate objectively and provide honest assessments.\n",
        "\n",
        "Context: {context_str}\n",
        "Question: {query_str}\n",
        "\n",
        "Assessment Rules:\n",
        "- For roles matching their background: Explain why they're suitable with evidence\n",
        "- For non-matching roles: Be honest about limited fit but suggest why\n",
        "- Always provide reasoning - never say \"cannot answer\"\n",
        "- Give specific examples from their experience\n",
        "- Keep responses concise (3-4 sentences max)\n",
        "- Reason well from over the whole context about the question and then answer\n",
        "- If answer not found in context, infer cautiously and provide insights\n",
        "\n",
        "Response format:\n",
        "- Direct answer and brief reasoning with evidence\n",
        "- If poor fit: suggest better alternatives\n",
        "\n",
        "Answer:\"\"\"\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def load_qa_engine(retriever, llm, memory):\n",
        "    \"\"\"Create enhanced query engine with memory support - FIXED VERSION\"\"\"\n",
        "\n",
        "    # ✅ CORRECT: Use from_args() factory method that supports memory\n",
        "    qa_engine = RetrieverQueryEngine.from_args(\n",
        "        retriever=retriever,\n",
        "        llm=llm,\n",
        "        memory=memory,\n",
        "        response_mode=\"tree_summarize\",\n",
        "        verbose=False\n",
        "    )\n",
        "\n",
        "    # Apply custom prompt template for enhanced reasoning\n",
        "    qa_engine.update_prompts({\n",
        "        \"response_synthesizer:summary_template\": CAREER_ADVISOR_PROMPT\n",
        "    })\n",
        "\n",
        "    return qa_engine\n",
        "\n",
        "def load_index(persist_dir='resume_index'):\n",
        "    \"\"\"Load persisted index\"\"\"\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=persist_dir)\n",
        "    index = load_index_from_storage(storage_context)\n",
        "    return index\n",
        "\n",
        "def build_agent(model_name, memory):\n",
        "    \"\"\"Build complete AI agent with enhanced reasoning capabilities\"\"\"\n",
        "    print(\"🔄 Loading model...\")\n",
        "    llm = load_model(model_name)\n",
        "\n",
        "    print(\"📂 Loading index...\")\n",
        "    index = load_index()\n",
        "\n",
        "    print(\"🔍 Building retriever...\")\n",
        "    retriever = build_retriever(index)\n",
        "\n",
        "    print(\"🤖 Creating enhanced QA engine...\")\n",
        "    qa = load_qa_engine(retriever, llm, memory)\n",
        "\n",
        "    print(\"✅ Agent ready with enhanced reasoning!\")\n",
        "    return qa\n",
        "\n",
        "# Usage\n",
        "enhanced_qa = build_agent(model_name, memory)\n"
      ],
      "metadata": {
        "id": "e_xUgRtK9kAj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170,
          "referenced_widgets": [
            "45525830f6a343368e3cb0bf6f73138b",
            "2e1502a57fe44486b9db2b7cf4d73493",
            "78e43b73886d477bbfe83b12e44ed74b",
            "4be6b7ec97e84a4fac026fdddd1a4573",
            "9ee1707c7d034f48a6b6549b0aba02be",
            "2c03fae6f9e9486db2f02d25ed079a52",
            "fa59cf37763b4371af7047d5573a9fd7",
            "111fd4917a4f4a53a759c10f8390ce4a",
            "29342c8faaab456684b3f77555bbfcf2",
            "51d9a6c6167c4c16906c3aea39abbd48",
            "44498007c1364fa79da5d6975af521e6"
          ]
        },
        "outputId": "1891243f-817f-4e6d-f794-3a33420c2614"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Loading model...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45525830f6a343368e3cb0bf6f73138b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📂 Loading index...\n",
            "Loading llama_index.core.storage.kvstore.simple_kvstore from resume_index/docstore.json.\n",
            "Loading llama_index.core.storage.kvstore.simple_kvstore from resume_index/index_store.json.\n",
            "🔍 Building retriever...\n",
            "🤖 Creating enhanced QA engine...\n",
            "✅ Agent ready with enhanced reasoning!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === SUPPRESS ALL WARNINGS ===\n",
        "import warnings\n",
        "import os\n",
        "import logging\n",
        "import time\n",
        "from typing import Dict, List\n",
        "\n",
        "# Suppress all Python warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=PendingDeprecationWarning)\n",
        "\n",
        "# Suppress transformers/HuggingFace warnings\n",
        "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "# Suppress PyTorch warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch\")\n",
        "\n",
        "# Suppress LlamaIndex warnings\n",
        "os.environ[\"LLAMA_INDEX_CACHE_DIR\"] = \"/tmp/llama_index_cache\"\n",
        "logging.getLogger(\"llama_index\").setLevel(logging.ERROR)\n",
        "\n",
        "# Suppress other common ML library warnings\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"sentence_transformers\").setLevel(logging.ERROR)\n",
        "\n",
        "\n",
        "def test_resume_qa_system(qa_engine, index=None):\n",
        "    \"\"\"\n",
        "    Enhanced testing suite for resume Q&A system with non-discriminative language\n",
        "    Tests the enhanced reasoning capabilities and response quality\n",
        "    \"\"\"\n",
        "\n",
        "    print(\"🚀 Enhanced Resume Q&A System Testing\")\n",
        "    print(\"✨ Testing with improved reasoning and analysis capabilities\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    results = {\n",
        "        'total_tests': 0,\n",
        "        'passed': 0,\n",
        "        'failed': 0,\n",
        "        'performance': {},\n",
        "        'section_coverage': {},\n",
        "        'quality_scores': {},\n",
        "        'reasoning_quality': {}\n",
        "    }\n",
        "\n",
        "    # === UPDATED CORE TEST QUESTIONS (Non-discriminative) ===\n",
        "    test_suite = {\n",
        "        'Basics': [\n",
        "            \"What is the candidate's email address?\",\n",
        "            \"Where is the candidate located?\",\n",
        "            \"What are the candidate's contact details?\"\n",
        "        ],\n",
        "        'Skills': [\n",
        "            \"What programming languages does the candidate know?\",\n",
        "            \"What AI/ML technologies has the candidate used?\",\n",
        "            \"What cloud platforms has the candidate worked with?\"\n",
        "        ],\n",
        "        'Experience': [\n",
        "            \"What companies has the candidate worked at?\",\n",
        "            \"What was the candidate's role at TechCorp Solutions?\",\n",
        "            \"How many years of experience does the candidate have?\"\n",
        "        ],\n",
        "        'Education': [\n",
        "            \"What degrees does the candidate have?\",\n",
        "            \"Where did the candidate study?\",\n",
        "            \"What is the candidate's educational background?\"\n",
        "        ],\n",
        "        'Certifications': [\n",
        "            \"What certifications does the candidate have?\",\n",
        "            \"Does the candidate have AWS certification?\",\n",
        "            \"What professional certifications are listed?\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    # === ENHANCED QUALITY VALIDATION ===\n",
        "    quality_checks = {\n",
        "        \"What certifications does the candidate have?\":\n",
        "            [\"AWS\", \"Google Cloud\", \"Kubernetes\", \"TensorFlow\", \"MongoDB\"],\n",
        "        \"What programming languages does the candidate know?\":\n",
        "            [\"Python\", \"Java\", \"Scala\", \"Go\", \"JavaScript\"],\n",
        "        \"What companies has the candidate worked at?\":\n",
        "            [\"TechCorp\", \"DataFlow\", \"InnovateLabs\", \"CloudTech\"]\n",
        "    }\n",
        "\n",
        "    # === REASONING QUALITY TESTS (New) ===\n",
        "    reasoning_tests = {\n",
        "        \"Is the candidate suitable for data analyst roles?\": {\n",
        "            \"should_contain\": [\"suitable\", \"qualified\", \"experience\", \"skills\"],\n",
        "            \"should_not_contain\": [\"cannot answer\", \"does not mention\", \"text does not contain\"],\n",
        "            \"reasoning_required\": True\n",
        "        },\n",
        "        \"What are the candidate's core strengths?\": {\n",
        "            \"should_contain\": [\"strength\", \"experience\", \"expertise\", \"skill\"],\n",
        "            \"should_not_contain\": [\"cannot\", \"does not\"],\n",
        "            \"reasoning_required\": True\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # === RUN CORE TESTS ===\n",
        "    all_response_times = []\n",
        "    section_success = {}\n",
        "\n",
        "    for section, questions in test_suite.items():\n",
        "        print(f\"\\n📋 Testing {section}\")\n",
        "        section_success[section] = {'passed': 0, 'total': len(questions)}\n",
        "\n",
        "        for question in questions:\n",
        "            results['total_tests'] += 1\n",
        "\n",
        "            try:\n",
        "                # Time the response\n",
        "                start_time = time.time()\n",
        "                response = qa_engine.query(question)\n",
        "                response_time = time.time() - start_time\n",
        "                all_response_times.append(response_time)\n",
        "\n",
        "                # Enhanced validation\n",
        "                answer = str(response)\n",
        "                is_valid = (\n",
        "                    len(answer) > 20 and  # Longer minimum for quality responses\n",
        "                    \"sorry\" not in answer.lower() and\n",
        "                    \"cannot answer\" not in answer.lower() and\n",
        "                    \"does not mention\" not in answer.lower()\n",
        "                )\n",
        "\n",
        "                if is_valid:\n",
        "                    results['passed'] += 1\n",
        "                    section_success[section]['passed'] += 1\n",
        "                    status = \"✅\"\n",
        "                else:\n",
        "                    results['failed'] += 1\n",
        "                    status = \"⚠️\"\n",
        "\n",
        "                print(f\"  {status} {question[:45]}... ({response_time:.2f}s)\")\n",
        "\n",
        "            except Exception as e:\n",
        "                results['failed'] += 1\n",
        "                print(f\"  ❌ {question[:45]}... Error: {str(e)[:30]}\")\n",
        "\n",
        "    # === QUALITY SCORING ===\n",
        "    print(f\"\\n⭐ Quality Analysis\")\n",
        "    quality_scores = []\n",
        "\n",
        "    for question, expected_keywords in quality_checks.items():\n",
        "        try:\n",
        "            response = qa_engine.query(question)\n",
        "            answer = str(response).lower()\n",
        "\n",
        "            found = [kw for kw in expected_keywords if kw.lower() in answer]\n",
        "            score = (len(found) / len(expected_keywords)) * 100\n",
        "            quality_scores.append(score)\n",
        "\n",
        "            print(f\"  📊 {question[:35]}... Score: {score:.0f}%\")\n",
        "\n",
        "        except Exception as e:\n",
        "            quality_scores.append(0)\n",
        "            print(f\"  ❌ Quality check failed: {e}\")\n",
        "\n",
        "    # === REASONING QUALITY TESTS (New) ===\n",
        "    print(f\"\\n🧠 Reasoning Quality Analysis\")\n",
        "    reasoning_scores = []\n",
        "\n",
        "    for question, criteria in reasoning_tests.items():\n",
        "        try:\n",
        "            response = qa_engine.query(question)\n",
        "            answer = str(response).lower()\n",
        "\n",
        "            # Check positive criteria\n",
        "            positive_score = sum(1 for term in criteria[\"should_contain\"] if term in answer)\n",
        "            positive_ratio = positive_score / len(criteria[\"should_contain\"])\n",
        "\n",
        "            # Check negative criteria (should be 0)\n",
        "            negative_score = sum(1 for term in criteria[\"should_not_contain\"] if term in answer)\n",
        "            negative_penalty = negative_score / len(criteria[\"should_not_contain\"])\n",
        "\n",
        "            # Calculate overall reasoning score\n",
        "            reasoning_score = max(0, (positive_ratio - negative_penalty) * 100)\n",
        "            reasoning_scores.append(reasoning_score)\n",
        "\n",
        "            status = \"🧠\" if reasoning_score >= 70 else \"⚠️\"\n",
        "            print(f\"  {status} {question[:35]}... Reasoning: {reasoning_score:.0f}%\")\n",
        "\n",
        "        except Exception as e:\n",
        "            reasoning_scores.append(0)\n",
        "            print(f\"  ❌ Reasoning test failed: {e}\")\n",
        "\n",
        "    # === PERFORMANCE METRICS ===\n",
        "    if all_response_times:\n",
        "        results['performance'] = {\n",
        "            'avg_response_time': sum(all_response_times) / len(all_response_times),\n",
        "            'max_response_time': max(all_response_times),\n",
        "            'min_response_time': min(all_response_times)\n",
        "        }\n",
        "\n",
        "    # === INDEX VALIDATION ===\n",
        "    if index:\n",
        "        try:\n",
        "            node_count = len(index.docstore.docs)\n",
        "            sections_found = set()\n",
        "            for node in index.docstore.docs.values():\n",
        "                if 'section' in node.metadata:\n",
        "                    sections_found.add(node.metadata['section'])\n",
        "\n",
        "            results['index_stats'] = {\n",
        "                'total_nodes': node_count,\n",
        "                'sections_found': list(sections_found)\n",
        "            }\n",
        "        except Exception as e:\n",
        "            results['index_error'] = str(e)\n",
        "\n",
        "    # === ENHANCED FINAL REPORT ===\n",
        "    print(f\"\\n📊 COMPREHENSIVE TEST SUMMARY\")\n",
        "    print(\"=\" * 35)\n",
        "\n",
        "    success_rate = (results['passed'] / results['total_tests']) * 100 if results['total_tests'] > 0 else 0\n",
        "    avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0\n",
        "    avg_reasoning = sum(reasoning_scores) / len(reasoning_scores) if reasoning_scores else 0\n",
        "\n",
        "    print(f\"🎯 Success Rate: {success_rate:.1f}% ({results['passed']}/{results['total_tests']})\")\n",
        "    print(f\"⭐ Quality Score: {avg_quality:.1f}%\")\n",
        "    print(f\"🧠 Reasoning Score: {avg_reasoning:.1f}%\")\n",
        "\n",
        "    if all_response_times:\n",
        "        print(f\"⚡ Avg Response: {results['performance']['avg_response_time']:.2f}s\")\n",
        "\n",
        "    if index:\n",
        "        print(f\"📂 Index Nodes: {results['index_stats']['total_nodes']}\")\n",
        "        print(f\"📋 Sections: {', '.join(results['index_stats']['sections_found'])}\")\n",
        "\n",
        "    # Section breakdown\n",
        "    print(f\"\\n📂 Section Performance:\")\n",
        "    for section, stats in section_success.items():\n",
        "        section_rate = (stats['passed'] / stats['total']) * 100\n",
        "        print(f\"  {section:12}: {section_rate:.0f}% ({stats['passed']}/{stats['total']})\")\n",
        "\n",
        "    # Enhanced system health assessment\n",
        "    overall_score = (success_rate + avg_quality + avg_reasoning) / 3\n",
        "\n",
        "    if overall_score >= 80 and avg_reasoning >= 70:\n",
        "        print(f\"\\n🟢 System Status: EXCELLENT (Enhanced reasoning working)\")\n",
        "    elif overall_score >= 70 and success_rate >= 80:\n",
        "        print(f\"\\n🟡 System Status: GOOD (Some reasoning improvements needed)\")\n",
        "    elif success_rate >= 60:\n",
        "        print(f\"\\n🟠 System Status: NEEDS ATTENTION (Reasoning capabilities limited)\")\n",
        "    else:\n",
        "        print(f\"\\n🔴 System Status: CRITICAL ISSUES (Major problems detected)\")\n",
        "\n",
        "    # Store reasoning results\n",
        "    results['reasoning_quality'] = {\n",
        "        'avg_reasoning_score': avg_reasoning,\n",
        "        'reasoning_tests_passed': sum(1 for score in reasoning_scores if score >= 70),\n",
        "        'total_reasoning_tests': len(reasoning_scores)\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "# === ENHANCED USAGE ===\n",
        "# Use with your enhanced agent instead of basic qa\n",
        "if 'enhanced_qa' in globals():\n",
        "    print(\"🚀 Testing with Enhanced QA Agent\")\n",
        "    test_results = test_resume_qa_system(enhanced_qa, index)\n",
        "else:\n",
        "    print(\"⚠️ Using basic QA engine - consider using enhanced_qa for better results\")\n",
        "    test_results = test_resume_qa_system(qa, index)\n",
        "\n",
        "# Enhanced results saving\n",
        "import json\n",
        "enhanced_results = {\n",
        "    **test_results,\n",
        "    'test_metadata': {\n",
        "        'test_version': 'enhanced_v2.0',\n",
        "        'reasoning_enabled': True,\n",
        "        'non_discriminative': True,\n",
        "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')\n",
        "    }\n",
        "}\n",
        "\n",
        "# Optional: Save enhanced results\n",
        "# with open('enhanced_test_results.json', 'w') as f:\n",
        "#     json.dump(enhanced_results, f, indent=2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MnxAd3VGqBq",
        "outputId": "6b1edde9-7f13-420a-d247-9f7730de9542"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🚀 Testing with Enhanced QA Agent\n",
            "🚀 Enhanced Resume Q&A System Testing\n",
            "✨ Testing with improved reasoning and analysis capabilities\n",
            "==================================================\n",
            "\n",
            "📋 Testing Basics\n",
            "  ✅ What is the candidate's email address?... (22.05s)\n",
            "  ✅ Where is the candidate located?... (23.06s)\n",
            "  ✅ What are the candidate's contact details?... (17.82s)\n",
            "\n",
            "📋 Testing Skills\n",
            "  ✅ What programming languages does the candidate... (22.67s)\n",
            "  ✅ What AI/ML technologies has the candidate use... (23.56s)\n",
            "  ✅ What cloud platforms has the candidate worked... (20.97s)\n",
            "\n",
            "📋 Testing Experience\n",
            "  ✅ What companies has the candidate worked at?... (48.19s)\n",
            "  ✅ What was the candidate's role at TechCorp Sol... (20.81s)\n",
            "  ✅ How many years of experience does the candida... (25.08s)\n",
            "\n",
            "📋 Testing Education\n",
            "  ✅ What degrees does the candidate have?... (21.45s)\n",
            "  ✅ Where did the candidate study?... (23.26s)\n",
            "  ✅ What is the candidate's educational backgroun... (23.49s)\n",
            "\n",
            "📋 Testing Certifications\n",
            "  ✅ What certifications does the candidate have?... (28.85s)\n",
            "  ✅ Does the candidate have AWS certification?... (17.84s)\n",
            "  ✅ What professional certifications are listed?... (37.35s)\n",
            "\n",
            "⭐ Quality Analysis\n",
            "  📊 What certifications does the candid... Score: 100%\n",
            "  📊 What programming languages does the... Score: 100%\n",
            "  📊 What companies has the candidate wo... Score: 100%\n",
            "\n",
            "🧠 Reasoning Quality Analysis\n",
            "  ⚠️ Is the candidate suitable for data ... Reasoning: 0%\n",
            "  🧠 What are the candidate's core stren... Reasoning: 100%\n",
            "\n",
            "📊 COMPREHENSIVE TEST SUMMARY\n",
            "===================================\n",
            "🎯 Success Rate: 100.0% (15/15)\n",
            "⭐ Quality Score: 100.0%\n",
            "🧠 Reasoning Score: 50.0%\n",
            "⚡ Avg Response: 25.10s\n",
            "📂 Index Nodes: 6\n",
            "📋 Sections: Experience, Skills, Education, Publications, Certifications, Basics\n",
            "\n",
            "📂 Section Performance:\n",
            "  Basics      : 100% (3/3)\n",
            "  Skills      : 100% (3/3)\n",
            "  Experience  : 100% (3/3)\n",
            "  Education   : 100% (3/3)\n",
            "  Certifications: 100% (3/3)\n",
            "\n",
            "🟡 System Status: GOOD (Some reasoning improvements needed)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# === SUPPRESS ALL WARNINGS ===\n",
        "import warnings\n",
        "import os\n",
        "import logging\n",
        "\n",
        "# Suppress all Python warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=PendingDeprecationWarning)\n",
        "\n",
        "# Suppress transformers/HuggingFace warnings\n",
        "os.environ[\"TRANSFORMERS_VERBOSITY\"] = \"error\"\n",
        "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
        "\n",
        "# Suppress PyTorch warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"torch\")\n",
        "\n",
        "# Suppress LlamaIndex warnings\n",
        "os.environ[\"LLAMA_INDEX_CACHE_DIR\"] = \"/tmp/llama_index_cache\"\n",
        "logging.getLogger(\"llama_index\").setLevel(logging.ERROR)\n",
        "\n",
        "# Suppress other common ML library warnings\n",
        "logging.getLogger(\"transformers\").setLevel(logging.ERROR)\n",
        "logging.getLogger(\"sentence_transformers\").setLevel(logging.ERROR)\n",
        "\n",
        "\n",
        "def detect_interaction_type(query):\n",
        "    \"\"\"Detect what type of interaction the user wants\"\"\"\n",
        "\n",
        "    query_lower = query.lower().strip()\n",
        "\n",
        "    # Greetings and casual interactions\n",
        "    greetings = ['hi', 'hello', 'hey', 'good morning', 'good afternoon', 'good evening']\n",
        "    casual_responses = ['thanks', 'thank you', 'ok', 'okay', 'cool', 'nice', 'great']\n",
        "\n",
        "    if query_lower in greetings:\n",
        "        return 'greeting'\n",
        "    elif query_lower in casual_responses:\n",
        "        return 'acknowledgment'\n",
        "    elif len(query.split()) <= 2 and query_lower in ['help', '?', 'info']:\n",
        "        return 'help'\n",
        "    else:\n",
        "        return 'question'\n",
        "\n",
        "\n",
        "def get_humane_response(query, interaction_type, qa_engine):\n",
        "    \"\"\"Generate appropriate responses based on interaction type\"\"\"\n",
        "\n",
        "    if interaction_type == 'greeting':\n",
        "        return \"\"\"👋 Hello! I'm here to help you learn about the candidate's background and qualifications.\n",
        "\n",
        "I can answer questions about their:\n",
        "• Technical skills and expertise\n",
        "• Work experience and achievements\n",
        "• Education and certifications\n",
        "• Suitability for specific roles\n",
        "\n",
        "What would you like to know about the candidate?\"\"\"\n",
        "\n",
        "    elif interaction_type == 'acknowledgment':\n",
        "        return \"😊 You're welcome! Feel free to ask me anything else about the candidate's resume.\"\n",
        "\n",
        "    elif interaction_type == 'help':\n",
        "        return \"\"\"💡 Here are some example questions you can ask:\n",
        "\n",
        "**Skills & Experience:**\n",
        "• \"What programming languages does the candidate know?\"\n",
        "• \"Tell me about their AI/ML experience\"\n",
        "• \"What cloud platforms have they worked with?\"\n",
        "\n",
        "**Career & Suitability:**\n",
        "• \"Is the candidate suitable for a data scientist role?\"\n",
        "• \"What are their core strengths?\"\n",
        "• \"What leadership experience do they have?\"\n",
        "\n",
        "**Specific Details:**\n",
        "• \"Where did the candidate study?\"\n",
        "• \"What certifications do they have?\"\n",
        "• \"What companies have they worked at?\"\n",
        "\n",
        "Just ask naturally - I'll understand! 🤖\"\"\"\n",
        "\n",
        "    else:  # It's a real question - SIMPLIFIED (no prompt engineering)\n",
        "        # ✅ MODIFIED: Direct query without additional prompting\n",
        "        # Since prompt engineering is handled in model loading\n",
        "        return qa_engine.query(query)\n",
        "\n",
        "\n",
        "def qa_assistant(query, qa_engine):\n",
        "    \"\"\"More humane QA assistant that recognizes different interaction types\"\"\"\n",
        "\n",
        "    # Check for exit commands\n",
        "    if query.lower().strip() in ['exit', 'quit', 'stop', 'q', 'bye', 'goodbye']:\n",
        "        return False\n",
        "\n",
        "    # Handle empty input\n",
        "    if not query.strip():\n",
        "        print(\"❓ Please enter a question or just say 'hi' to get started!\")\n",
        "        return True\n",
        "\n",
        "    # Detect interaction type and respond appropriately\n",
        "    try:\n",
        "        interaction_type = detect_interaction_type(query)\n",
        "\n",
        "        if interaction_type in ['greeting', 'acknowledgment', 'help']:\n",
        "            print(\"💭 ...\")  # Brief thinking indicator for casual interactions\n",
        "        else:\n",
        "            print(\"🔍 Analyzing the candidate's background...\")\n",
        "\n",
        "        response = get_humane_response(query, interaction_type, qa_engine)\n",
        "        print(f\"🤖 {response}\")\n",
        "        return True\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Sorry, I encountered an error: {e}\")\n",
        "        print(\"💡 Try rephrasing your question or type 'help' for examples.\")\n",
        "        return True\n",
        "\n",
        "\n",
        "def start_qa_session(qa_engine):\n",
        "    \"\"\"Start a more humane interactive QA session\"\"\"\n",
        "    print(\"🤖 Resume Q&A Assistant\")\n",
        "    print(\"✨ Ask me anything about the candidate's background!\")\n",
        "    print(\"💬 Just say 'hi' to get started, or ask any question directly\")\n",
        "    print(\"🚪 Type 'quit' to exit\\n\")\n",
        "\n",
        "    question_count = 0\n",
        "    greeting_given = False\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            user_question = input(\"💬 You: \")\n",
        "\n",
        "            # Track if user has been greeted\n",
        "            if not greeting_given and detect_interaction_type(user_question) != 'greeting':\n",
        "                greeting_given = True\n",
        "\n",
        "            if not qa_assistant(user_question, qa_engine):\n",
        "                if question_count == 0:\n",
        "                    print(f\"\\n👋 Thanks for stopping by!\")\n",
        "                elif question_count == 1:\n",
        "                    print(f\"\\n📊 Hope that was helpful! Feel free to come back anytime.\")\n",
        "                else:\n",
        "                    print(f\"\\n📊 Great questions! We covered {question_count} topics about the candidate.\")\n",
        "                break\n",
        "\n",
        "            # Only count substantive questions\n",
        "            if detect_interaction_type(user_question) == 'question':\n",
        "                question_count += 1\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\n⚠️ Session interrupted. Have a great day! 👋\")\n",
        "            break\n",
        "\n",
        "\n",
        "# Usage\n",
        "start_qa_session(enhanced_qa)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AO6SzxPeNfaW",
        "outputId": "ee87023d-8ea1-4b76-8353-c9a54b4edce9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🤖 Resume Q&A Assistant\n",
            "✨ Ask me anything about the candidate's background!\n",
            "💬 Just say 'hi' to get started, or ask any question directly\n",
            "🚪 Type 'quit' to exit\n",
            "\n",
            "💬 You: are they suitable for data analyst?\n",
            "🔍 Analyzing the candidate's background...\n",
            "🤖 \n",
            "\n",
            "The provided text does not describe any roles related to data analysis, therefore I cannot provide an assessment on whether Alexandra Chen is suitable for such roles.\n",
            "\n",
            "However, based on her experience and skills, she appears to be well-suited for positions involving AI/ML engineering, software engineering, or data science. Her strong technical background, expertise in various programming languages and frameworks, and ability to work on complex projects make her a strong candidate for these roles.\n",
            "💬 You: what do you think based on her skills?\n",
            "🔍 Analyzing the candidate's background...\n",
            "🤖 \n",
            "\n",
            "Alexandra Chen has a strong background in AI/ML engineering and backend development, making her well-suited for roles in various fields. Her expertise in Python, TensorFlow, and machine learning pipelines aligns well with positions involving data analytics, AI model development, and backend systems. Additionally, her experience in distributed systems, microservices architecture, and cloud-native technologies makes her a strong candidate for roles in software engineering and data science. However, her limited experience in specific areas such as data engineering and DevOps may require additional training or mentorship. Overall, Alexandra Chen has a strong potential for success in various roles related to AI/ML and backend development, and her skills and experience make her a suitable candidate for many positions in the technology industry.\n",
            "💬 You: based on her skills and related exp is she suitable for data analyst roles?\n",
            "🔍 Analyzing the candidate's background...\n",
            "🤖 \n",
            "\n",
            "Based on the provided text, Alexandra Chen is not well-suited for data analyst roles. While she has strong technical skills in AI/ML and backend engineering, her experience and background suggest that she would be more successful in roles involving her technical expertise and leadership skills rather than data analysis.\n",
            "\n",
            "While she does have some experience with data analysis tools and techniques, such as Spark and Python, her primary focus has been on engineering and leadership roles rather than data analysis. Her lack of experience in data analysis specifically, combined with her strong background in engineering and leadership, makes her more suitable for roles that require her technical expertise and leadership abilities rather than data analysis.\n",
            "💬 You: and if we take her for hr roles will it be a mistake??\n",
            "🔍 Analyzing the candidate's background...\n",
            "🤖 \n",
            "\n",
            "Based on the provided context, Alexandra Chen has a strong profile for roles in AI/ML engineering, backend engineering, and data science. Her extensive experience in designing and implementing scalable, high-performance systems and her proficiency in various technologies such as TensorFlow, PyTorch, and Python make her well-suited for roles involving AI/ML development and implementation. Additionally, her strong educational background and certifications in relevant fields further bolster her suitability for these roles.\n",
            "\n",
            "However, she may not be ideally suited for roles that require strong customer service or sales skills, as her experience does not indicate any direct customer-facing roles. While she could potentially be trained for such roles, it may not be the best fit given her current skillset and experience.\n",
            "\n",
            "Overall, based on the available context, Alexandra Chen has a strong potential for success in roles related to AI/ML engineering, backend engineering, and data science. While she may not be the perfect fit for roles requiring strong customer service or sales skills, there are other roles where her skills and experience would be more aligned with her strengths.\n",
            "💬 You: so she won't do good in Human Resources Roles?\n",
            "🔍 Analyzing the candidate's background...\n",
            "🤖 \n",
            "\n",
            "The text does not provide information about Human Resources Roles, therefore I cannot provide an answer to the question. However, based on the candidate's experience and skills, she would likely be more suited for roles in technology and engineering fields rather than Human Resources Roles.\n",
            "💬 You: what are their core strengths?\n",
            "🔍 Analyzing the candidate's background...\n",
            "🤖 \n",
            "\n",
            "Alexandra Chen has a strong track record in designing and implementing scalable, high-performance backend systems and AI/ML solutions. Her core strengths lie in her expertise in distributed systems, microservices architecture, machine learning pipelines, and cloud-native technologies. She is also proficient in various programming languages, including Python, Java, and TensorFlow, and has experience working with industry-standard tools such as Kafka, Beam, and Airflow. Additionally, her strong leadership and communication skills enable her to effectively lead and mentor junior engineers. Overall, her extensive experience and skillset make her well-suited for roles involving complex software development and AI implementation.\n",
            "💬 You: list out the programming lang skills of their's\n",
            "🔍 Analyzing the candidate's background...\n",
            "🤖 \n",
            "\n",
            "The candidate has strong proficiency in various programming languages, including Python, Java, Scala, Go, C++, JavaScript/TypeScript, SQL, R, and TensorFlow. They have extensive experience in using these languages to develop and implement scalable, high-performance backend systems and AI/ML solutions. Their expertise in these languages enables them to effectively contribute to projects involving data engineering, machine learning, and software engineering.\n",
            "💬 You: what frameworks did they work with?\n",
            "🔍 Analyzing the candidate's background...\n",
            "🤖 \n",
            "\n",
            "The candidate has experience working with various frameworks including Python, FastAPI, TensorFlow, Apache Kafka, Apache Beam, PyTorch, OpenCV, Flask, Docker, and Kubernetes. They have also worked with frameworks such as Java Spring Boot, Scala, Spark MLlib, and MongoDB.\n",
            "💬 You: did the used any containerization tools in work exp?\n",
            "🔍 Analyzing the candidate's background...\n",
            "🤖 \n",
            "\n",
            "The text does not mention containerization tools used in work experience, therefore I cannot answer this question.\n",
            "💬 You: take a look at her skills and say again\n",
            "🔍 Analyzing the candidate's background...\n",
            "🤖 \n",
            "\n",
            "Alexandra Chen has a strong background in Senior Backend AI Engineer roles and is well-suited for positions that require expertise in designing and implementing scalable, high-performance backend systems and AI/ML solutions. Her extensive experience in distributed systems, microservices architecture, machine learning pipelines, and cloud-native technologies makes her an ideal candidate for roles involving complex system design and implementation. However, she may not be as well-suited for roles that require specific industry expertise or domain knowledge, such as roles in the healthcare or finance industries.\n",
            "💬 You: does she have any containerization skills?\n",
            "🔍 Analyzing the candidate's background...\n",
            "🤖 \n",
            "\n",
            "The text does not describe any containerization skills of the candidate, therefore I cannot provide an answer to this question.\n",
            "💬 You: exit\n",
            "\n",
            "📊 Great questions! We covered 11 topics about the candidate.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mJw_yGhuOXQZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "82c89249"
      },
      "source": [
        "# Resume Analysis and Q&A System\n",
        "\n",
        "This notebook implements a system for extracting information from a resume PDF, indexing the extracted data, and providing a conversational Q&A interface to query the resume's content.\n",
        "\n",
        "## System Components\n",
        "\n",
        "1.  **Dependency Installation**:\n",
        "    -   Installs necessary libraries including `llama-index`, `sentence-transformers`, `bitsandbytes`, and specific LlamaIndex integrations for HuggingFace models.\n",
        "\n",
        "2.  **Llama Cloud Extractor**:\n",
        "    -   Utilizes `llama_cloud_services.LlamaExtract` to load a pre-configured extraction agent (`Precise_Resume_extract`) using a provided project ID and API key.\n",
        "    -   This agent is designed to parse structured information (like skills, experience, education) from resume documents.\n",
        "    -   The loaded agent's data schema is printed to show the expected output structure.\n",
        "\n",
        "3.  **Resume Data Extraction**:\n",
        "    -   The loaded `extractor` agent is used to process a specific resume file (`/content/Backend AI Engineer Resume Template - Claude.pdf`).\n",
        "    -   The extracted structured data (in JSON format) is stored in the `parsed_data` variable and printed.\n",
        "\n",
        "4.  **JSON to Text Conversion**:\n",
        "    -   Custom Python functions (`flatten_json` and `resume_json_to_text`) are defined to convert the nested JSON output from the extractor into a flattened, human-readable markdown-like text format.\n",
        "    -   This converted text (`resume_text`) is then printed.\n",
        "\n",
        "5.  **Text Sectioning**:\n",
        "    -   A function `extract_sections` is used to split the `resume_text` into logical sections based on markdown headers (e.g., \"Basics\", \"Skills\", \"Experience\").\n",
        "    -   This creates a dictionary (`sections`) where keys are section titles and values are the text content of each section.\n",
        "\n",
        "6.  **Embedding Model Setup**:\n",
        "    -   Configures the embedding model used by LlamaIndex for creating vector representations of the text data.\n",
        "    -   The `sentence-transformers/all-MiniLM-L6-v2` model is set as the default embedding model in `Settings`.\n",
        "\n",
        "7.  **Node Creation with Custom Chunking**:\n",
        "    -   The `create_nodes_with_custom_chunking` function processes the text `sections`.\n",
        "    -   For each section, it creates a `Document` object with the section content and metadata (the section name).\n",
        "    -   It uses a `SentenceSplitter` configured to keep each section as a single node by setting a large `chunk_size`.\n",
        "    -   This results in a list of `nodes`, where each node represents a distinct section of the resume.\n",
        "    -   Node metadata and text previews are printed for verification.\n",
        "\n",
        "8.  **Vector Store Indexing**:\n",
        "    -   A `VectorStoreIndex` is created directly from the list of `nodes`. This indexes the content of each resume section, making it searchable based on vector similarity.\n",
        "    -   The index is then persisted to disk in the `resume_index` directory for later loading.\n",
        "\n",
        "9.  **Index Verification and Analysis**:\n",
        "    -   Code cells verify the basic properties of the created index (type, node count, ID).\n",
        "    -   The `analyze_index_contents` function provides a more detailed breakdown of the index, including total characters, average characters per node, and statistics for each section.\n",
        "\n",
        "10. **Index Loading**:\n",
        "    -   Demonstrates how to load the persisted index from the `resume_index` directory using `StorageContext`.\n",
        "    -   Verification is performed to ensure the loaded index has the correct number of nodes.\n",
        "\n",
        "11. **Hugging Face LLM Loading**:\n",
        "    -   A function `load_model` is defined to load a Hugging Face Language Model (`google/gemma-7b-it`) using `HuggingFaceLLM`.\n",
        "    -   4-bit quantization (`BitsAndBytesConfig`) is applied to reduce memory usage.\n",
        "\n",
        "12. **Retriever and Query Engine Setup**:\n",
        "    -   A `retriever` is built from the loaded `index` to fetch relevant nodes based on a query (`similarity_top_k=6`).\n",
        "    -   A custom `CAREER_ADVISOR_PROMPT` is defined to guide the LLM's response, instructing it to act as a career advisor, provide reasoning, and adhere to specific formatting rules.\n",
        "    -   A `ChatMemoryBuffer` is initialized to maintain conversation history.\n",
        "    -   The `load_qa_engine` function creates a `RetrieverQueryEngine` from the retriever, LLM, and memory, and updates the response synthesis prompt with the `CAREER_ADVISOR_PROMPT`.\n",
        "\n",
        "13. **Agent Building**:\n",
        "    -   The `build_agent` function orchestrates the loading of the model, index, retriever, and query engine, creating a complete AI agent ready for interaction.\n",
        "\n",
        "14. **Automated Testing Suite**:\n",
        "    -   The `test_resume_qa_system` function provides a comprehensive evaluation of the QA system.\n",
        "    -   It runs a set of predefined questions across different resume sections.\n",
        "    -   Includes checks for successful response generation, quality scoring based on expected keywords, and a novel \"reasoning quality\" assessment to evaluate how well the agent adheres to the career advisor prompt's instructions for providing justified answers.\n",
        "    -   Prints a detailed summary of test results, including success rates, quality scores, reasoning scores, performance metrics, and index statistics.\n",
        "\n",
        "15. **Interactive QA Assistant**:\n",
        "    -   The `qa_assistant` and `start_qa_session` functions provide a user-friendly command-line interface.\n",
        "    -   `detect_interaction_type` identifies if the user input is a greeting, acknowledgment, help request, or a question.\n",
        "    -   `get_humane_response` provides tailored responses for casual interactions or uses the `qa_engine` for questions.\n",
        "    -   The `start_qa_session` function loops, taking user input and using the `qa_assistant` to provide responses until the user types an exit command.\n",
        "    -   This allows for natural language interaction with the indexed resume content.\n",
        "\n",
        "This system demonstrates a complete pipeline for processing unstructured resume data, structuring it, indexing it for efficient retrieval, and building a conversational interface with enhanced reasoning capabilities using LlamaIndex and Hugging Face models."
      ]
    }
  ]
}